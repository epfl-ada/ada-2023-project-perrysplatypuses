{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.imdb_ratings import movies_with_imdb_rating\n",
    "from utils.cluster_interpretation import plot_topic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What isn't included in this notebook\n",
    "\n",
    "This project required a lot of preprocessing, which is an interesting task, but is not related to the research questions. In this notebook we will focus on the research questions only.\n",
    "\n",
    "For extracting characters and their attributes from the plot texts, refer to `extract_character_attributes.ipynb`.\n",
    "\n",
    "For the clustering method please refer to `clustering.ipynb`, there you can find the methods comparison and the pipeline for characters clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters =  pd.read_csv(\n",
    "    'data/character_clusters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    'data/MovieSummaries/movie.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'title', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    ")\n",
    "\n",
    "actors = pd.read_csv(\n",
    "    'data/MovieSummaries/character.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'release_date', 'character', 'date_of_birth', 'sex', 'height', '.','actor','age','character_map','..','...','....']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_data = pd.read_csv('data/cpi_data.csv', )\n",
    "cpi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_name(names1, names2):\n",
    "    names1 = names1.values\n",
    "    names2 = names2.values\n",
    "    flag = []\n",
    "    for i in range(len(names1)):\n",
    "        flag.append(names1[i] in names2[i])\n",
    "    return flag\n",
    "\n",
    "\n",
    "actors_and_characters = characters.merge(actors, how='left', left_on='wiki_id', right_on='wiki_id').dropna(subset=['character_y'])\n",
    "\n",
    "actors_and_characters = actors_and_characters[same_name(actors_and_characters['character_x'], actors_and_characters['character_y'])]\n",
    "actors_and_characters['character'] = actors_and_characters['character_x']\n",
    "actors_and_characters = actors_and_characters.drop(columns=['character_x', 'character_y'])\n",
    "actors_and_characters = actors_and_characters[['character', 'actor', 'cluster', 'wiki_id', 'release_date', 'date_of_birth', 'sex', 'height', 'age', 'adj', 'active', 'patient']]\n",
    "actors_and_characters.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_revenue(year, revenue):\n",
    "    if year in cpi_data['year']:\n",
    "        cpi = cpi_data[cpi_data['year'] == year]['cpi'][0]\n",
    "    else:\n",
    "        cpi = 1\n",
    "    return (revenue /  cpi)*100\n",
    "\n",
    "\n",
    "map_dict_to_list = lambda x: [value for key, value in eval(x).items()]\n",
    "release_year = lambda x: pd.to_numeric(x.str.replace(r'-\\d{2}-\\d{2}$', '', regex=True).str.replace(r'-\\d{2}$', '', regex=True))\n",
    "\n",
    "movies['languages'] = movies['languages'].apply(map_dict_to_list)\n",
    "movies['countries'] = movies['countries'].apply(map_dict_to_list)\n",
    "movies['genres'] = movies['genres'].apply(map_dict_to_list)\n",
    "\n",
    "movies[\"release_year\"] = release_year(movies['release_date'])\n",
    "movies[\"release_year\"] = movies['release_year'].apply(lambda x: x if x > 1800 else x + 1000)\n",
    "\n",
    "movies['discounted_revenue'] = movies.apply(lambda x: discount_revenue(x.release_year, x.revenue), axis=1)\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Script takes time to run, so we will use saved version instead\n",
    "movies_with_rating = movies_with_imdb_rating(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_rating = pd.read_csv(\n",
    "    'data/movies_with_rating.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"languages\": map_dict_to_list,\n",
    "        \"countries\": map_dict_to_list,\n",
    "        \"genres\": map_dict_to_list\n",
    "        }\n",
    "    )\n",
    "    \n",
    "movies_with_rating['release_year'] = release_year(movies_with_rating['release_date'])\n",
    "movies_with_rating['discounted_revenue'] = movies_with_rating.apply(lambda x: discount_revenue(x.release_year, x.revenue), axis=1)\n",
    "\n",
    "movies_with_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of movies: {len(movies)}\")\n",
    "print(f\"Number of movies with revenue: {movies['revenue'].notna().sum()}\")\n",
    "print(f\"Number of movies with rating: {len(movies_with_rating)}\")\n",
    "print(f\"Number of movies with rating and revenue: {movies_with_rating['revenue'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of characters with archetypes: {len(characters)}\")\n",
    "print(f\"Number of actors: {len(actors)}\")\n",
    "print(f\"Number of actors with the characters who have an archetype: {len(actors_and_characters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of actors with the characters who have an archetype in the movies with revenue and rating: {len(actors_and_characters[actors_and_characters['wiki_id'].isin(movies_with_rating[movies_with_rating['revenue'].notna()]['wiki_id'])])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coutries_distr = movies.explode('countries').groupby('countries').size()\n",
    "coutries_distr_with_rating = movies_with_rating.explode('countries').groupby('countries').size()\n",
    "coutries_distr_with_rating_and_revenue = movies_with_rating[movies_with_rating['revenue'].notna()].explode('countries').groupby('countries').size()\n",
    "\n",
    "coutries = list(set(\n",
    "    coutries_distr.sort_values(ascending=False)[:20].index.to_list() \n",
    "    + coutries_distr_with_rating.sort_values(ascending=False)[:20].index.to_list() \n",
    "    + coutries_distr_with_rating_and_revenue.sort_values(ascending=False)[:20].index.to_list()))\n",
    "\n",
    "coutries_distr = coutries_distr.loc[coutries].sort_values(ascending=True)\n",
    "coutries = coutries_distr.index.to_list() \n",
    "coutries_distr_with_rating = coutries_distr_with_rating.loc[coutries]\n",
    "coutries_distr_with_rating_and_revenue = coutries_distr_with_rating_and_revenue.loc[coutries]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.title('Top of movie production countries')\n",
    "\n",
    "plt.barh(coutries_distr.index, coutries_distr.values, label='all movies')\n",
    "plt.barh(coutries_distr_with_rating.index, coutries_distr_with_rating.values, label='movies with rating')\n",
    "plt.barh(coutries_distr_with_rating_and_revenue.index, coutries_distr_with_rating_and_revenue.values, label='movies with rating and revenue')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that most of the movies in the dataset are made in the US, moreover, we have much less data for movies with revenue and this data is't distributed prportionally to the overall number of movies produced in the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.groupby('release_year').size().plot(figsize=(15, 5), title='Number of released movies', label='number of released movies')\n",
    "plt.xticks(np.arange(1890, 2021, 7))\n",
    "\n",
    "plt.axvspan(1914, 1918, alpha=0.3, label='World War I')\n",
    "plt.axvspan(1929, 1939, alpha=0.3, label='Great Depression', color='green')\n",
    "plt.axvspan(1939, 1945, alpha=0.3, label='World War II')\n",
    "plt.axvspan(1961.2, 1961.3, alpha=0.3, label='First space flight', color='purple')\n",
    "plt.axvspan(2007, 2008, alpha=0.3, label='Global Financial Crisis', color='green')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have much data before 1910-s and after 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters interpretation\n",
    "To interpret clusters, we can use the function `plot_topic_distribution` to see the topics with the largest probabilities to be in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topic_distribution(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historycal trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_and_movies = characters.merge(movies, left_on='wiki_id', right_on='wiki_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_count = characters_and_movies.groupby('release_year').size().reset_index(name='movie_count')\n",
    "movies_count = movies_count[movies_count['movie_count'] >= 15]\n",
    "movies_count.plot(x='release_year', y='movie_count')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: We decide to analyze trends where there is a stable abundance of data, and remove movies before 1932 and tha last two years (2013-2014). For further analysis we are selecting important clusters (by relative popularity or changes in popularity) but this selection is skewed by the years where there is little data since that gives a very high proportion for every cluster. So the early clusters will appear very significant despite that not being the case (if e.g. there are only a handful of movies, the archetype distribution is not very interesting). Therefore the filtered subset is used, not only for plot, but also for cluster ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archetype_counts = characters_and_movies[characters_and_movies['release_year'].isin(movies_count['release_year'])].groupby(['release_year', 'cluster']).size().reset_index(name='character_count')\n",
    "archetype_counts = archetype_counts.pivot(index='release_year', columns='cluster', values='character_count').fillna(0)\n",
    "archetype_counts.plot(legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_archetype_counts = (archetype_counts)/(archetype_counts.values.sum(1).reshape(-1, 1))\n",
    "normalized_archetype_counts.plot(legend=False)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top archetypes\n",
    "\n",
    "- By the highest sum of normalized frequency (popularity)\n",
    "- By the biggest range in normalized frequency (changes in popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of normalized frequency\n",
    "\n",
    "top_clusters = normalized_archetype_counts.sum(0).sort_values(ascending=False)[:10].index.values\n",
    "top_clusters_archetype_counts = normalized_archetype_counts[top_clusters]\n",
    "top_clusters_archetype_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clusters_archetype_counts.plot(figsize=(12, 6))\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(top_clusters_archetype_counts.index[::5], rotation=45, ha='right')\n",
    "plt.xlim([1931, 2013])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Normalized character count')\n",
    "plt.title('Normalized character counts by cluster: subset 1')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------\n",
    "n = 10 # sliding average window size\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Iterate over clusters and plot a line for each\n",
    "for cluster in top_clusters:\n",
    "    x = top_clusters_archetype_counts[cluster]\n",
    "    x_avg = np.convolve(x, np.ones(n)/n, mode='valid')\n",
    "    y = top_clusters_archetype_counts.index\n",
    "    y_1 = y[round(n/2):-(n-round(n/2))+1]\n",
    "    plt.plot(y_1, x_avg, label=f'Cluster {cluster}', marker='', linewidth=0.7)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(top_clusters_archetype_counts.index[::5], rotation=45, ha='right')\n",
    "plt.xlim([1931, 2013])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Normalized character count')\n",
    "plt.title(f'Normalized character counts by cluster: subset 1. Sliding average (n={n})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_info(n):\n",
    "    print('Cluster: ', n)\n",
    "    top = characters_and_movies[(characters_and_movies['cluster'] == n) & (characters_and_movies['revenue'] > 5e8)]\n",
    "    top = top.sort_values(by='revenue', ascending=False).head(5)\n",
    "    print(top[['title', 'character']])\n",
    "    plot_topic_distribution(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster_info(19)\n",
    "print_cluster_info(12)\n",
    "print_cluster_info(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biggest range in normalized frequency\n",
    "\n",
    "top_clusters = normalized_archetype_counts.apply(np.ptp).sort_values(ascending=False)[:10].index.values\n",
    "top_clusters_archetype_counts = normalized_archetype_counts[top_clusters]\n",
    "top_clusters_archetype_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clusters_archetype_counts.plot(figsize=(12, 6))\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(top_clusters_archetype_counts.index[::5], rotation=45, ha='right')\n",
    "plt.xlim([1931, 2013])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Normalized character count')\n",
    "plt.title('Normalized character counts by cluster: subset 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------\n",
    "n = 10 # sliding average window size\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Iterate over clusters and plot a line for each\n",
    "for cluster in top_clusters:\n",
    "    x = top_clusters_archetype_counts[cluster]\n",
    "    x_avg = np.convolve(x, np.ones(n)/n, mode='valid')\n",
    "    y = top_clusters_archetype_counts.index\n",
    "    y_1 = y[round(n/2):-(n-round(n/2))+1]\n",
    "    plt.plot(y_1, x_avg, label=f'Cluster {cluster}', marker='', linewidth=0.7)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(top_clusters_archetype_counts.index[::5], rotation=45, ha='right')\n",
    "plt.xlim([1931, 2013])\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Normalized character count')\n",
    "plt.title(f'Normalized character counts by cluster: subset 1. Sliding average (n={n})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster_info(10)\n",
    "print_cluster_info(5)\n",
    "print_cluster_info(38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cultural preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie success based on the archetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actors success based on the archetypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, We'll make a table of what archetypal characters each film contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\"wiki_id\",\"Freebase movie ID\",\" Movie name\",\"Movie release date\", \"MovieBoxOfficeRevenue\",\"Movie runtime\",\"Movie languages\",\"Movie countries\",\"Movie genres\" ]\n",
    "df_movies = pd.read_csv(\"data/MovieSummaries/movie.metadata.tsv\", sep='\\t',names= colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_clusters = pd.read_csv(\"data/character_clusters.csv\")\n",
    "df_clusters = df_clusters.drop(df_clusters.columns[[0,3,4,5]], axis=1) # dropping unneccesary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging datasets\n",
    "df_merged = pd.merge(df_clusters, df_movies, on='wiki_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column for each archetypes. And they will take binary number.\n",
    "for i in range(1,51):\n",
    "    df_merged['archetype{}'.format(i)]=df_merged['cluster'].map(lambda x: 1 if x== i else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the movie include the archetype[i], then the column archetype[i] will take 1 , otherwise 0.\n",
    "def dummy(s):\n",
    "    if sum(s)>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# this is just an opperation for getting Box office value after a groupby operation.\n",
    "def boxoffice(s):\n",
    "    return sum(s)/len(s)\n",
    "\n",
    "string= ''    \n",
    "for i in range(1,51):\n",
    "    string = string + '\\'archetype' +str(i) +'\\':dummy,'\n",
    "string = string[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moviearchetypes = df_merged.groupby('wiki_id').agg({'MovieBoxOfficeRevenue':boxoffice,'archetype1':dummy,'archetype2':dummy,'archetype3':dummy,'archetype4':dummy,'archetype5':dummy,'archetype6':dummy,'archetype7':dummy,'archetype8':dummy,'archetype9':dummy,'archetype10':dummy,'archetype11':dummy,'archetype12':dummy,'archetype13':dummy,'archetype14':dummy,'archetype15':dummy,'archetype16':dummy,'archetype17':dummy,'archetype18':dummy,'archetype19':dummy,'archetype20':dummy,'archetype21':dummy,'archetype22':dummy,'archetype23':dummy,'archetype24':dummy,'archetype25':dummy,'archetype26':dummy,'archetype27':dummy,'archetype28':dummy,'archetype29':dummy,'archetype30':dummy,'archetype31':dummy,'archetype32':dummy,'archetype33':dummy,'archetype34':dummy,'archetype35':dummy,'archetype36':dummy,'archetype37':dummy,'archetype38':dummy,'archetype39':dummy,'archetype40':dummy,'archetype41':dummy,'archetype42':dummy,'archetype43':dummy,'archetype44':dummy,'archetype45':dummy,'archetype46':dummy,'archetype47':dummy,'archetype48':dummy,'archetype49':dummy,'archetype50':dummy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the raw without Box Office value\n",
    "df_moviearchetypes = df_moviearchetypes.dropna(subset=['MovieBoxOfficeRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieBoxOfficeRevenue</th>\n",
       "      <th>archetype1</th>\n",
       "      <th>archetype2</th>\n",
       "      <th>archetype3</th>\n",
       "      <th>archetype4</th>\n",
       "      <th>archetype5</th>\n",
       "      <th>archetype6</th>\n",
       "      <th>archetype7</th>\n",
       "      <th>archetype8</th>\n",
       "      <th>archetype9</th>\n",
       "      <th>...</th>\n",
       "      <th>archetype41</th>\n",
       "      <th>archetype42</th>\n",
       "      <th>archetype43</th>\n",
       "      <th>archetype44</th>\n",
       "      <th>archetype45</th>\n",
       "      <th>archetype46</th>\n",
       "      <th>archetype47</th>\n",
       "      <th>archetype48</th>\n",
       "      <th>archetype49</th>\n",
       "      <th>archetype50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28984353</th>\n",
       "      <td>11647000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273390</th>\n",
       "      <td>12974636.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157481</th>\n",
       "      <td>116000000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031573</th>\n",
       "      <td>12313323.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27111227</th>\n",
       "      <td>105648706.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21381088</th>\n",
       "      <td>11546932.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74862</th>\n",
       "      <td>4517000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233576</th>\n",
       "      <td>216614388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932836</th>\n",
       "      <td>16192320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434738</th>\n",
       "      <td>267005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MovieBoxOfficeRevenue  archetype1  archetype2  archetype3  \\\n",
       "wiki_id                                                               \n",
       "28984353             11647000.0           0           0           0   \n",
       "5273390              12974636.0           0           0           0   \n",
       "157481              116000000.0           0           1           0   \n",
       "1031573              12313323.0           1           0           0   \n",
       "27111227            105648706.0           0           0           0   \n",
       "21381088             11546932.0           0           0           0   \n",
       "74862                 4517000.0           0           0           0   \n",
       "1233576             216614388.0           0           0           0   \n",
       "2932836              16192320.0           0           0           0   \n",
       "434738                 267005.0           0           0           0   \n",
       "\n",
       "          archetype4  archetype5  archetype6  archetype7  archetype8  \\\n",
       "wiki_id                                                                \n",
       "28984353           0           0           0           0           0   \n",
       "5273390            0           0           0           0           0   \n",
       "157481             0           0           0           1           0   \n",
       "1031573            0           0           0           0           0   \n",
       "27111227           0           0           0           0           0   \n",
       "21381088           0           0           0           0           0   \n",
       "74862              0           0           0           0           0   \n",
       "1233576            0           0           0           0           0   \n",
       "2932836            0           0           0           0           0   \n",
       "434738             1           0           0           0           0   \n",
       "\n",
       "          archetype9  ...  archetype41  archetype42  archetype43  archetype44  \\\n",
       "wiki_id               ...                                                       \n",
       "28984353           0  ...            0            0            0            0   \n",
       "5273390            0  ...            0            0            0            0   \n",
       "157481             0  ...            0            0            0            0   \n",
       "1031573            0  ...            0            0            0            0   \n",
       "27111227           0  ...            1            1            0            0   \n",
       "21381088           0  ...            0            0            0            0   \n",
       "74862              0  ...            0            0            0            0   \n",
       "1233576            0  ...            0            0            0            0   \n",
       "2932836            0  ...            0            0            0            0   \n",
       "434738             0  ...            0            0            0            0   \n",
       "\n",
       "          archetype45  archetype46  archetype47  archetype48  archetype49  \\\n",
       "wiki_id                                                                     \n",
       "28984353            0            0            0            0            0   \n",
       "5273390             1            0            0            1            0   \n",
       "157481              1            0            0            0            0   \n",
       "1031573             0            0            0            0            0   \n",
       "27111227            0            0            0            0            0   \n",
       "21381088            0            1            0            0            0   \n",
       "74862               0            0            0            0            0   \n",
       "1233576             0            0            0            0            0   \n",
       "2932836             0            0            0            0            0   \n",
       "434738              0            0            0            0            0   \n",
       "\n",
       "          archetype50  \n",
       "wiki_id                \n",
       "28984353            0  \n",
       "5273390             0  \n",
       "157481              0  \n",
       "1031573             0  \n",
       "27111227            0  \n",
       "21381088            0  \n",
       "74862               0  \n",
       "1233576             0  \n",
       "2932836             0  \n",
       "434738              0  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#table will look like this\n",
    "df_moviearchetypes.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got the data.\n",
    "\n",
    "Our goal is to create a linear regression model with each archetype as a variable to predict the log of the box office revenue.\n",
    "\n",
    "We will use linear regression model and least square method to fit it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply log to boxoffice\n",
    "df_moviearchetypes['MovieBoxOfficeRevenue'] = df_moviearchetypes['MovieBoxOfficeRevenue'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of archetypes\n",
    "n = 50\n",
    "\n",
    "model_str = \"MovieBoxOfficeRevenue ~ \"\n",
    "for i in range(1,n+1):\n",
    "    model_str += \"C(archetype\" + str(i) + \")+\"\n",
    "\n",
    "model_str_without_interaction = model_str.strip(\"+\")\n",
    "\n",
    "for i in range(1,n):\n",
    "    for j in range(i+1, n+1):\n",
    "        model_str += \"C(archetype\" + str(i) + \"):C(archetype\" + str(j) + \")+\"\n",
    "\n",
    "model_str = model_str.strip(\"+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "mod = smf.ols(formula = model_str_without_interaction, data = df_moviearchetypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model (adding a random seed ensuring consistency)\n",
    "np.random.seed(2)\n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>MovieBoxOfficeRevenue</td> <th>  R-squared:         </th> <td>   0.108</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                     <td>OLS</td>          <th>  Adj. R-squared:    </th> <td>   0.101</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>Least Squares</td>     <th>  F-statistic:       </th> <td>   15.38</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>               <td>Tue, 19 Dec 2023</td>    <th>  Prob (F-statistic):</th> <td>6.86e-119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                   <td>14:30:40</td>        <th>  Log-Likelihood:    </th> <td> -13066.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>        <td>  6280</td>         <th>  AIC:               </th> <td>2.623e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>            <td>  6230</td>         <th>  BIC:               </th> <td>2.657e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                <td>    49</td>         <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>nonrobust</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & MovieBoxOfficeRevenue & \\textbf{  R-squared:         } &     0.108  \\\\\n",
       "\\textbf{Model:}            &          OLS          & \\textbf{  Adj. R-squared:    } &     0.101  \\\\\n",
       "\\textbf{Method:}           &     Least Squares     & \\textbf{  F-statistic:       } &     15.38  \\\\\n",
       "\\textbf{Date:}             &    Tue, 19 Dec 2023   & \\textbf{  Prob (F-statistic):} & 6.86e-119  \\\\\n",
       "\\textbf{Time:}             &        14:30:40       & \\textbf{  Log-Likelihood:    } &   -13066.  \\\\\n",
       "\\textbf{No. Observations:} &           6280        & \\textbf{  AIC:               } & 2.623e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &           6230        & \\textbf{  BIC:               } & 2.657e+04  \\\\\n",
       "\\textbf{Df Model:}         &             49        & \\textbf{                     } &            \\\\\n",
       "\\textbf{Covariance Type:}  &       nonrobust       & \\textbf{                     } &            \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary().tables[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is very low.\n",
    "The model is not accurate.\n",
    "But we can still select which of those archetypes might have an effect on box office revenue by considering the p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will add interaction terms and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare the model\n",
    "mod = smf.ols(formula = model_str, data = df_moviearchetypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>MovieBoxOfficeRevenue</td> <th>  R-squared:         </th> <td>   0.273</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                     <td>OLS</td>          <th>  Adj. R-squared:    </th> <td>   0.097</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>Least Squares</td>     <th>  F-statistic:       </th> <td>   1.553</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>               <td>Tue, 19 Dec 2023</td>    <th>  Prob (F-statistic):</th> <td>8.79e-25</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                   <td>14:30:56</td>        <th>  Log-Likelihood:    </th> <td> -12423.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>        <td>  6280</td>         <th>  AIC:               </th> <td>2.729e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>            <td>  5056</td>         <th>  BIC:               </th> <td>3.555e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                <td>  1223</td>         <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>        <td>nonrobust</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & MovieBoxOfficeRevenue & \\textbf{  R-squared:         } &     0.273  \\\\\n",
       "\\textbf{Model:}            &          OLS          & \\textbf{  Adj. R-squared:    } &     0.097  \\\\\n",
       "\\textbf{Method:}           &     Least Squares     & \\textbf{  F-statistic:       } &     1.553  \\\\\n",
       "\\textbf{Date:}             &    Tue, 19 Dec 2023   & \\textbf{  Prob (F-statistic):} &  8.79e-25  \\\\\n",
       "\\textbf{Time:}             &        14:30:56       & \\textbf{  Log-Likelihood:    } &   -12423.  \\\\\n",
       "\\textbf{No. Observations:} &           6280        & \\textbf{  AIC:               } & 2.729e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &           5056        & \\textbf{  BIC:               } & 3.555e+04  \\\\\n",
       "\\textbf{Df Model:}         &           1223        & \\textbf{                     } &            \\\\\n",
       "\\textbf{Covariance Type:}  &       nonrobust       & \\textbf{                     } &            \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is still low but  better than the last one. We can conclude that revenue prediction by archetype combination could be prospective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be nice if someone could implement regression with three archetypes interaction term. In that case, we cannot use \"smf.ols\" anymore because of the number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to find out important archetypes without assuming linear model.  We will do variance-based analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have N variables of archetypes, box office revenue will be like $f(x_1,x_2\\dotsi x_N,\\epsilon)$.\\\n",
    "Note that each variable of $x_1,x_2\\dotsi x_N$ will take $0$ or $1$ and $\\epsilon$ denotes effects of other variables. And we assume $\\epsilon$ is independent of other variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f can be decomposed uniquely in a following way.\n",
    "\\begin{align}\n",
    "    f(\\boldsymbol{x}) &= f_\\phi + \\sum_{1<=i<=N}f_i(x_i)+ \\sum_{1<=i<j<=N}f_{i,j}(x_i,x_j)+\\sum_{1<=i<j<k<=N}f_{i,j,k}(x_i,x_j,x_k)+\\dotsi + f_\\epsilon(\\epsilon)\\nonumber\\\\\n",
    "    &= \\sum_{u\\subset\\{1,\\dotsi,N\\}}f_u(\\boldsymbol{x}_u) + f_\\epsilon(\\epsilon)\\\\\n",
    "    f_\\phi &= \\mathbb{E}[f] \\nonumber\\\\\n",
    "    f_j(x_j) &= \\mathbb{E}[f|x_j]-f_\\phi \\nonumber\\\\\n",
    "    f_{i,j}(x_i,x_j) &= \\mathbb{E}[f|x_i,x_j]-f_i(x_i)-f_j(x_j) - f_\\phi \\nonumber \\\\\n",
    "    &\\vdots \\nonumber\n",
    "\\end{align}\n",
    "This have good properties.\n",
    "+ $\\mathbb{E}[f_u] = 0$ when $u\\subset \\{1,\\dotsi,N\\}$ and $u\\neq \\phi$\n",
    "+ $\\mathbb{C}[f_u,f_v]=0$ when $u,v\\subset \\{1,\\dotsi,N\\}$ and $u\\neq v$\n",
    "\n",
    "Using these properties we can prove the following fact.\n",
    "\\begin{equation}\n",
    "    \\mathbb{V}[f] = \\sum_{u\\subset\\{1,\\dotsi,N\\}}\\mathbb{V}[f_u] + \\mathbb{V}[f_\\epsilon]\\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see ,for example, $\\mathbb{V}[f_1]$ as an effect of archetype 1 itself and $\\mathbb{V}[f_{1,2}]$ as an  effect of archetype 1and archetype 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate$ \\mathbb{V}[f_u]$.\n",
    "The basic ideas is that if archetype sets $u\\subset\\{1,\\dotsi,N\\}$ is important, then the variance will be small when you fix $\\boldsymbol{x}_u$.\\\n",
    "We will resample from data and do Monte-Carlo estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $  \\boldsymbol{x} = (\\boldsymbol{x}_{u}, \\boldsymbol{x}_{-u})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\mathbb{V}[f_u]} = \\frac{1}{N}\\sum_{n=1}^N f(\\boldsymbol{x}_{-u}^{(n,1)},\\boldsymbol{x}_{u}^{(n)})f(\\boldsymbol{x}_{-u}^{(n,2)},\\boldsymbol{x}_{u}^{(n)}) - \\hat{\\mu}^{(1)}  \\hat{\\mu}^{(2)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "where $(\\boldsymbol{x}_{u}^{(n)})_{n\\in[1:N]}$\n",
    "is an i.i.d. sample with the distribution of $\\boldsymbol{x}_{u}$\n",
    "and where\n",
    "$\\boldsymbol{x}_{-u}^{(n,1)}$and $\\boldsymbol{x}_{-u}^{(n,2)}$\n",
    "conditionally to $\\boldsymbol{x}_{u}$ are independent with the distribution\n",
    "of $\\boldsymbol{x}_{-u}$ conditionally to $\\boldsymbol{x}_{u} = \\boldsymbol{x}_{u}^{(n)}$\\\\\n",
    "$\\hat{\\mu}$ is an estimation of $\\mathbb{E}[f]$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "musquare = df_moviearchetypes.sample(N,replace=True).mean()[\"MovieBoxOfficeRevenue\"] *  df_moviearchetypes.sample(N,replace=True).mean()[\"MovieBoxOfficeRevenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_Order_Variance =np.zeros(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of archetype1: 0.5351473757099257\n",
      "variance of archetype2: 1.0253526388780756\n",
      "variance of archetype3: 0.482157889426162\n",
      "variance of archetype4: 0.09263158522617232\n",
      "variance of archetype5: -0.7343832539433492\n",
      "variance of archetype6: 0.2885012579785098\n",
      "variance of archetype7: -0.564543107984889\n",
      "variance of archetype8: 0.3356120813805319\n",
      "variance of archetype9: -0.543109643362925\n",
      "variance of archetype10: 0.5556218414711793\n",
      "variance of archetype11: 0.7279874148010208\n",
      "variance of archetype12: 0.02198422673660616\n",
      "variance of archetype13: 0.04017146373911373\n",
      "variance of archetype14: -0.5894218075685558\n",
      "variance of archetype15: 0.6052226355710104\n",
      "variance of archetype16: 0.04062695747552425\n",
      "variance of archetype17: 0.39916996832818086\n",
      "variance of archetype18: 0.7971355037618082\n",
      "variance of archetype19: 0.4339910117784598\n",
      "variance of archetype20: 0.06470905004687211\n",
      "variance of archetype21: 0.6418715203192278\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (N):\n\u001b[1;32m      4\u001b[0m     sample_u1 \u001b[38;5;241m=\u001b[39m df_moviearchetypes\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     sample_u2 \u001b[38;5;241m=\u001b[39m  \u001b[43mdf_moviearchetypes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_moviearchetypes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchetype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample_u1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchetype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     variance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(sample_u1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieBoxOfficeRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(sample_u2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieBoxOfficeRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m variance \u001b[38;5;241m=\u001b[39m variance \u001b[38;5;241m/\u001b[39m N\u001b[38;5;241m-\u001b[39mmusquare\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,51):\n",
    "    variance = 0\n",
    "    for j in range (N):\n",
    "        sample_u1 = df_moviearchetypes.sample(1)\n",
    "        sample_u2 =  df_moviearchetypes[df_moviearchetypes[\"archetype\"+str(i)] == int(sample_u1[\"archetype\"+str(i)])].sample(1)\n",
    "        variance += float(sample_u1[\"MovieBoxOfficeRevenue\"])* float(sample_u2[\"MovieBoxOfficeRevenue\"])\n",
    "    variance = variance / N-musquare\n",
    "    print(\"variance of archetype\"+str(i)+ \":\",variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of archetype1;2: 0.5907112778327814\n",
      "variance of archetype1;3: 1.2670019285209264\n",
      "variance of archetype1;4: -2.2119972090181363\n",
      "variance of archetype1;5: 0.8758552480368849\n",
      "variance of archetype1;6: 0.5942124222127632\n",
      "variance of archetype1;7: 0.0994114885908175\n",
      "variance of archetype1;8: -4.350592083745028\n",
      "variance of archetype1;9: -0.21193617869346326\n",
      "variance of archetype1;10: 0.40431840122590756\n",
      "variance of archetype1;11: -1.0237386156005073\n",
      "variance of archetype1;12: -1.7591856645370854\n",
      "variance of archetype1;13: 2.5959443883609765\n",
      "variance of archetype1;14: -0.9429249915636433\n",
      "variance of archetype1;15: -1.9728112381641267\n",
      "variance of archetype1;16: -1.2582149304878953\n",
      "variance of archetype1;17: 0.4920602396436493\n",
      "variance of archetype1;18: -0.8715193063255811\n",
      "variance of archetype1;19: -0.8036296428593914\n",
      "variance of archetype1;20: 0.5607470482593158\n",
      "variance of archetype1;21: -3.150038128474023\n",
      "variance of archetype1;22: 2.1474459755730777\n",
      "variance of archetype1;23: 0.8345420938495636\n",
      "variance of archetype1;24: 0.9446597795314915\n",
      "variance of archetype1;25: -0.10340891216543469\n",
      "variance of archetype1;26: 0.32489868896118423\n",
      "variance of archetype1;27: -1.9212971199550566\n",
      "variance of archetype1;28: 2.6214982303193324\n",
      "variance of archetype1;29: -1.487299095530716\n",
      "variance of archetype1;30: 1.729769095830136\n",
      "variance of archetype1;31: -1.8821644172942342\n",
      "variance of archetype1;32: -0.03318619448765503\n",
      "variance of archetype1;33: 1.5626984005493796\n",
      "variance of archetype1;34: 0.8735056684895426\n",
      "variance of archetype1;35: 0.016222802134223002\n",
      "variance of archetype1;36: -4.44268750170761\n",
      "variance of archetype1;37: 0.33844409790418695\n",
      "variance of archetype1;38: 0.17463023228941665\n",
      "variance of archetype1;39: -1.5248857086196494\n",
      "variance of archetype1;40: 1.6699816581277673\n",
      "variance of archetype1;41: 1.942694587533083\n",
      "variance of archetype1;42: -0.9128030938566667\n",
      "variance of archetype1;43: 1.7650223566874956\n",
      "variance of archetype1;44: -0.6565977344473026\n",
      "variance of archetype1;45: -0.3665204242997788\n",
      "variance of archetype1;46: 1.8867837262079092\n",
      "variance of archetype1;47: 0.42952813988358685\n",
      "variance of archetype1;48: -2.1841421395778866\n",
      "variance of archetype1;49: -0.16651653658453824\n",
      "variance of archetype1;50: 1.215607990951412\n",
      "variance of archetype2;3: -2.678698993377111\n",
      "variance of archetype2;4: -0.2285011725334698\n",
      "variance of archetype2;5: -3.599745952622868\n",
      "variance of archetype2;6: 0.8497360502381639\n",
      "variance of archetype2;7: -3.3658397136314875\n",
      "variance of archetype2;8: 0.9100266939132666\n",
      "variance of archetype2;9: -1.7348286612972856\n",
      "variance of archetype2;10: 0.7249915785186545\n",
      "variance of archetype2;11: -2.1222091451567735\n",
      "variance of archetype2;12: 2.3726199684699623\n",
      "variance of archetype2;13: -0.13904612346561862\n",
      "variance of archetype2;14: 2.6380404173862644\n",
      "variance of archetype2;15: -0.16572665568423872\n",
      "variance of archetype2;16: -2.0407077563945677\n",
      "variance of archetype2;17: -0.2100307569929214\n",
      "variance of archetype2;18: -2.397645354129793\n",
      "variance of archetype2;19: -0.8561743370295289\n",
      "variance of archetype2;20: 0.08980374418246129\n",
      "variance of archetype2;21: 1.192459472262044\n",
      "variance of archetype2;22: -3.703541061585838\n",
      "variance of archetype2;23: -1.1404759212955469\n",
      "variance of archetype2;24: -1.0007211350614398\n",
      "variance of archetype2;25: 1.0940757516025315\n",
      "variance of archetype2;26: 1.5095539840166339\n",
      "variance of archetype2;27: 0.8318064080692693\n",
      "variance of archetype2;28: -1.25515229957864\n",
      "variance of archetype2;29: 2.8636315948860442\n",
      "variance of archetype2;30: -1.4547141745059662\n",
      "variance of archetype2;31: -3.753539662953358\n",
      "variance of archetype2;32: -0.9896793347646735\n",
      "variance of archetype2;33: 3.405276931164906\n",
      "variance of archetype2;34: -0.9749732383387482\n",
      "variance of archetype2;35: 0.4653863163543406\n",
      "variance of archetype2;36: 3.1493480790401804\n",
      "variance of archetype2;37: -0.49732038822162394\n",
      "variance of archetype2;38: 2.29357674164919\n",
      "variance of archetype2;39: -2.3452947047676957\n",
      "variance of archetype2;40: -1.0345761457926415\n",
      "variance of archetype2;41: 1.0686640455379006\n",
      "variance of archetype2;42: 0.19455933585612684\n",
      "variance of archetype2;43: -3.4541076889799456\n",
      "variance of archetype2;44: -1.3756008355812241\n",
      "variance of archetype2;45: 0.4483364723430441\n",
      "variance of archetype2;46: 1.0655854225169605\n",
      "variance of archetype2;47: 1.1643882115487827\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m variance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (N):\n\u001b[0;32m----> 5\u001b[0m     sample_u1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf_moviearchetypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     sample_u2 \u001b[38;5;241m=\u001b[39m  df_moviearchetypes[ (df_moviearchetypes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchetype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(sample_u1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchetype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)]) ) \u001b[38;5;241m&\u001b[39m (df_moviearchetypes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchetype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(j)] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(sample_u1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchetype\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(j)]) )]\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     variance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(sample_u1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieBoxOfficeRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(sample_u2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieBoxOfficeRevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.10/site-packages/pandas/core/generic.py:5774\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   5771\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m   5773\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39msample(obj_len, size, replace, weights, rs)\n\u001b[0;32m-> 5774\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[1;32m   5777\u001b[0m     result\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(result))\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.10/site-packages/pandas/core/generic.py:3871\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3862\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3863\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_copy is deprecated and will be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m always returns a copy, so there is no need to specify this.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3865\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   3866\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   3867\u001b[0m     )\n\u001b[1;32m   3869\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_take((), kwargs)\n\u001b[0;32m-> 3871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.10/site-packages/pandas/core/generic.py:3886\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3879\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3880\u001b[0m \u001b[38;5;124;03mInternal version of the `take` allowing specification of additional args.\u001b[39;00m\n\u001b[1;32m   3881\u001b[0m \n\u001b[1;32m   3882\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3883\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3886\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3888\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3891\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.10/site-packages/pandas/core/internals/managers.py:978\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    975\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    977\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.10/site-packages/pandas/core/internals/managers.py:770\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    767\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(new_blocks, new_axes, new_refs, parent\u001b[38;5;241m=\u001b[39mparent)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;66;03m# We can avoid the need to rebuild these\u001b[39;00m\n\u001b[0;32m--> 770\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblknos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,50):\n",
    "    for j in range(i+1,51):\n",
    "        variance = 0\n",
    "        for k in range (N):\n",
    "            sample_u1 = df_moviearchetypes.sample(1)\n",
    "            sample_u2 =  df_moviearchetypes[ (df_moviearchetypes[\"archetype\"+str(i)] == int(sample_u1[\"archetype\"+str(i)]) ) & (df_moviearchetypes[\"archetype\"+str(j)] == int(sample_u1[\"archetype\"+str(j)]) )].sample(1)\n",
    "            variance += float(sample_u1[\"MovieBoxOfficeRevenue\"])* float(sample_u2[\"MovieBoxOfficeRevenue\"])\n",
    "        variance = variance / N - musquare\n",
    "        print(\"variance of archetype\"+str(i)+\";\"+str(j)+ \":\",variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can tell if $\\hat{\\mathbb{V}[f_u]}$ is big, archetype sets $u$ might have significant effect on revenue wheter positively or negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
