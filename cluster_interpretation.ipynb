{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.clustering import get_lda_clusters, get_vocab, word_topics_clustering, sort_meaningful, get_trf_clusters, topic_count\n",
    "from utils.clustering_evaluation import get_characters_with_tv_trop_info, variation_of_information, group_labels_by_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters =  pd.read_csv(\n",
    "    'data/character_clusters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\n",
    "    'data/MovieSummaries/movie.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'title', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    ")\n",
    "\n",
    "characters_and_movies = characters.merge(movies, how='left', on='wiki_id')\n",
    "characters_and_movies = characters_and_movies[characters_and_movies['revenue'] > 1e7]\n",
    "characters_and_movies = characters_and_movies #[['wiki_id', 'title', 'character', 'cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_and_movies[['wiki_id', 'title', 'character', 'cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lor_characters = characters_and_movies[characters_and_movies['title'].str.contains('Lord of the Rings')][['wiki_id', 'title', 'character', 'cluster', 'adj', 'active', 'patient']]\n",
    "lor_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = json.load(open('data/words_by_topic.json', 'r'))\n",
    "lda_components = np.load('data/lda_components.npy')\n",
    "with open('topics_description.txt', 'r') as f:\n",
    "    topics_names = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distribution(cluster, lda_components, topics_names):\n",
    "    features = ['adjective', 'active verb', 'patient verb']\n",
    "\n",
    "    cluster_components = lda_components[cluster]\n",
    "    top_topics = np.argsort(cluster_components)[-1:-21:-1]\n",
    "    topic_to_probability = {}\n",
    "    for i in top_topics:\n",
    "        feature = features[i // 200]\n",
    "        topic_to_probability[feature + ': ' + topics_names[i % 200]] = cluster_components[i]\n",
    "    return topic_to_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(topic_distribution(0, lda_components, topics_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(lor_characters['cluster'].values):\n",
    "    print(lor_characters[lor_characters['cluster']==i])\n",
    "    topic_distr = topic_distribution(i, lda_components, topics_names)\n",
    "    y_pos = np.arange(20)\n",
    "    plt.barh(y_pos, list(topic_distr.values()))\n",
    "    plt.yticks(y_pos, labels=list(topic_distr.keys()))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xscale('log')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
