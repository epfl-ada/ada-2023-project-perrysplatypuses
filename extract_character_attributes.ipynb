{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.character_attributes_extraction import character_names_from_text, character_attributes_from_text, character_active_verbs_from_text, character_patient_verbs_from_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots =  pd.read_csv(\n",
    "    'data/MovieSummaries/plot_summaries.txt', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'plot']\n",
    ")\n",
    "\n",
    "plots['plot'] = plots['plot'].apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "plots.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract characters names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy\n",
    "\n",
    "[Spacy](https://spacy.io/usage/linguistic-features) is a really nice library that allows to do many nlp tasks easilly.\n",
    "We will use named entity recognition and dependency parsing the most. Also we will probably use built-in word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"As Gregor Samsa awoke one morning from uneasy dreams he found himself transformed in his bed into an enormous insect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plots.loc[51]['plot']\n",
    "print(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_attributes_from_text(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_active_verbs_from_text(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features for characters in each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# it takes 5 hours 22 minutes to run \n",
    "\n",
    "character_list = []\n",
    "\n",
    "for index, row in tqdm([row for row in plots.iterrows()]):\n",
    "    plot = row['plot'] \n",
    "    character_names = character_names_from_text(plot)\n",
    "    character_attributes = character_attributes_from_text(plot)\n",
    "    character_active_verbs = character_active_verbs_from_text(plot)\n",
    "    character_patient_verbs = character_patient_verbs_from_text(plot)\n",
    "    for name in character_names:\n",
    "        character_list.append(\n",
    "            {\n",
    "                'wiki_id': row['wiki_id'],\n",
    "                'character': name,\n",
    "                'adj': character_attributes.get(name, []),\n",
    "                'active': character_active_verbs.get(name, []),\n",
    "                'patient': character_patient_verbs.get(name, []),\n",
    "            }\n",
    "        )\n",
    "\n",
    "character_df = pd.DataFrame(character_list)\n",
    "character_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "character_df.to_csv('data/character_attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "character_df[character_df['active'].map(len)>5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.character_attributes_extraction import attributes2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters =  pd.read_csv(\n",
    "    'data/character_attributes.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in characters.head().iterrows():\n",
    "        print(\" \".join([str(len(l)) for l in attributes2vec(r)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
