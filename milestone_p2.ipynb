{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.183730Z",
     "iopub.status.busy": "2023-11-16T22:04:05.183555Z",
     "iopub.status.idle": "2023-11-16T22:04:05.197566Z",
     "shell.execute_reply": "2023-11-16T22:04:05.197108Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.199836Z",
     "iopub.status.busy": "2023-11-16T22:04:05.199502Z",
     "iopub.status.idle": "2023-11-16T22:04:05.594478Z",
     "shell.execute_reply": "2023-11-16T22:04:05.593913Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/EPFL/Fall 2023/ADA/project_repo/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.clustering import get_lda_clusters, get_vocab, word_topics_clustering, sort_meaningful, get_trf_clusters, topic_count\n",
    "from utils.clustering_evaluation import get_characters_with_tv_trop_info, variation_of_information, group_labels_by_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering methods comparison\n",
    "\n",
    "We use Variation of Information between our clusters and golden clusters from TV Tropes as suggested in [Learning Latent Personas of Film Characters](http://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf). This way we can compare our methods' performance with the original method performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA based clustering\n",
    "For the character names and linguistic features extraction pipeline, please refer to `extract_character_attributes.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>adj</th>\n",
       "      <th>active</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Peeta Mellark</td>\n",
       "      <td>[son]</td>\n",
       "      <td>[take, reveal, mean, form, present, beg, tell]</td>\n",
       "      <td>[force]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Cato</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kill]</td>\n",
       "      <td>[encounter, wound, shoot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Katniss</td>\n",
       "      <td>[]</td>\n",
       "      <td>[take, survive, drop, warn, run, shoot, presen...</td>\n",
       "      <td>[give, find, torment, spare, force, tell, warn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Rue</td>\n",
       "      <td>[die]</td>\n",
       "      <td>[draw, care, draw, trap]</td>\n",
       "      <td>[hear, stab, comfort, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Seneca Crane</td>\n",
       "      <td>[Gamemaker]</td>\n",
       "      <td>[change, lock]</td>\n",
       "      <td>[summon, convince]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wiki_id      character          adj  \\\n",
       "0  31186339  Peeta Mellark        [son]   \n",
       "1  31186339           Cato           []   \n",
       "2  31186339        Katniss           []   \n",
       "3  31186339            Rue        [die]   \n",
       "4  31186339   Seneca Crane  [Gamemaker]   \n",
       "\n",
       "                                              active  \\\n",
       "0     [take, reveal, mean, form, present, beg, tell]   \n",
       "1                                             [kill]   \n",
       "2  [take, survive, drop, warn, run, shoot, presen...   \n",
       "3                           [draw, care, draw, trap]   \n",
       "4                                     [change, lock]   \n",
       "\n",
       "                                           patient  \n",
       "0                                          [force]  \n",
       "1                        [encounter, wound, shoot]  \n",
       "2  [give, find, torment, spare, force, tell, warn]  \n",
       "3                      [hear, stab, comfort, kill]  \n",
       "4                               [summon, convince]  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_attributes =  pd.read_csv(\n",
    "    'data/character_attributes.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "# select only the characters who have at least 3 liguistic features\n",
    "characters_attributes = sort_meaningful(characters_attributes, 3)\n",
    "\n",
    "characters_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_check, tv_tropes = get_characters_with_tv_trop_info(characters_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25 topics, 25 archetypes': 6.2466797099799205,\n",
       " '25 topics, 50 archetypes': 5.721030072070011,\n",
       " '25 topics, 100 archetypes': 5.2078476164448135,\n",
       " '50 topics, 25 archetypes': 6.3319648575061835,\n",
       " '50 topics, 50 archetypes': 5.666473591455292,\n",
       " '50 topics, 100 archetypes': 4.976150571899939,\n",
       " '100 topics, 25 archetypes': 6.349160556531042,\n",
       " '100 topics, 50 archetypes': 5.607356379575675,\n",
       " '100 topics, 100 archetypes': 4.898739702618948}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agglomerative_clusters_n = [25, 50, 100]\n",
    "n_components = [25, 50, 100]\n",
    "\n",
    "configs = {}\n",
    "config_base = {'characters': characters_to_check, 'min_freq': 5, 'max_freq':0.9}\n",
    "\n",
    "for alg_n in agglomerative_clusters_n:\n",
    "    for n in n_components:\n",
    "        config = config_base.copy()\n",
    "        config['clustering_algo'] = AgglomerativeClustering(n_clusters=alg_n, metric='cosine', linkage='complete')\n",
    "        config['n_components'] = n\n",
    "        configs[f'{alg_n} topics, {n} archetypes'] = config\n",
    "\n",
    "results_lda = {}\n",
    "for k, config in configs.items():\n",
    "    clusters = get_lda_clusters(**config)\n",
    "    results_lda[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_lda[k]}')\n",
    "\n",
    "clear_output(wait=True)\n",
    "results_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the results are even better (K=100, P=100, 5.42 in the paper and 4.9 here) than the results from the [paper](http://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf). That could indicate that using word2vec embeddings and Agglomerative clustering of the words to topics might be better suited for dividing the words into topics for the purpose of personas extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT based clustering\n",
    "\n",
    "For the embedding extraction see `utils/archive/transformer_embeddings.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6002183</td>\n",
       "      <td>Horton</td>\n",
       "      <td>[1.0488402843475342, 0.3811729848384857, 0.645...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6002183</td>\n",
       "      <td>Ned McDodd</td>\n",
       "      <td>[-0.5622232556343079, -0.2521360516548157, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6002183</td>\n",
       "      <td>JoJo</td>\n",
       "      <td>[-0.7999439835548401, -0.4102073311805725, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6002183</td>\n",
       "      <td>Sally</td>\n",
       "      <td>[0.7803803086280823, -0.7006192207336426, 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6002183</td>\n",
       "      <td>LaRue</td>\n",
       "      <td>[-0.038770418614149094, 0.219954714179039, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wiki_id   character                                                emb\n",
       "0  6002183      Horton  [1.0488402843475342, 0.3811729848384857, 0.645...\n",
       "1  6002183  Ned McDodd  [-0.5622232556343079, -0.2521360516548157, -0....\n",
       "2  6002183        JoJo  [-0.7999439835548401, -0.4102073311805725, 0.6...\n",
       "3  6002183       Sally  [0.7803803086280823, -0.7006192207336426, 0.32...\n",
       "4  6002183       LaRue  [-0.038770418614149094, 0.219954714179039, -0...."
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_with_trf_emb =  pd.read_csv(\n",
    "    'data/trf_embeddings_for_labeled_characters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"emb\": lambda x: [float(k) for k in x.strip(\"[]\").replace(\"'\",\"\").split(\", \")]\n",
    "        }\n",
    "    )\n",
    "# Leave only those, who we compared on the previous step\n",
    "characters_with_trf_emb = characters_with_trf_emb[characters_with_trf_emb['wiki_id'].isin(characters_to_check['wiki_id'].values)]\n",
    "\n",
    "characters_with_trf_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_check_trf, tv_tropes = get_characters_with_tv_trop_info(characters_with_trf_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25 archetypes, agglomerative clustering': 6.126084917715467,\n",
       " '25 archetypes, kmeans clustering': 6.295232973029424,\n",
       " '50 archetypes, agglomerative clustering': 5.5954496618130625,\n",
       " '50 archetypes, kmeans clustering': 5.668679717784783,\n",
       " '100 archetypes, agglomerative clustering': 4.936886689856702,\n",
       " '100 archetypes, kmeans clustering': 4.812142996551314}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_trf = {}\n",
    "for n in n_components:\n",
    "    k = f'{n} archetypes, agglomerative clustering'\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=n, metric='euclidean', linkage='complete')\n",
    "    clusters = get_trf_clusters(characters_to_check_trf, agglomerative)\n",
    "    results_trf[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_trf[k]}')\n",
    "\n",
    "    k = f'{n} archetypes, kmeans clustering'\n",
    "    kmeans = KMeans(n_clusters=n)\n",
    "    clusters = get_trf_clusters(characters_to_check_trf, kmeans)\n",
    "    results_trf[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_trf[k]}')\n",
    "\n",
    "clear_output(wait=True)\n",
    "results_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of BERT embeddings based clustering are also better than the results from the paper. Still, obtaining these embeddings is slow, and the difference between this and previous method is not that big, so we will stick to the faster and more interpretable LDA based method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "For the clusterization pipeline as well as the different clustering methods comparison refer to `clustering.ipynb`. For our initial analysis we will use 50 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.597362Z",
     "iopub.status.busy": "2023-11-16T22:04:05.596898Z",
     "iopub.status.idle": "2023-11-16T22:04:05.941635Z",
     "shell.execute_reply": "2023-11-16T22:04:05.940975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>adj</th>\n",
       "      <th>active</th>\n",
       "      <th>patient</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Peeta Mellark</td>\n",
       "      <td>[son]</td>\n",
       "      <td>[take, reveal, mean, form, present, beg, tell]</td>\n",
       "      <td>[force]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Cato</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kill]</td>\n",
       "      <td>[encounter, wound, shoot]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Katniss</td>\n",
       "      <td>[]</td>\n",
       "      <td>[take, survive, drop, warn, run, shoot, presen...</td>\n",
       "      <td>[give, find, torment, spare, force, tell, warn]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Rue</td>\n",
       "      <td>[die]</td>\n",
       "      <td>[draw, care, draw, trap]</td>\n",
       "      <td>[hear, stab, comfort, kill]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Seneca Crane</td>\n",
       "      <td>[Gamemaker]</td>\n",
       "      <td>[change, lock]</td>\n",
       "      <td>[summon, convince]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wiki_id      character          adj  \\\n",
       "0  31186339  Peeta Mellark        [son]   \n",
       "1  31186339           Cato           []   \n",
       "2  31186339        Katniss           []   \n",
       "3  31186339            Rue        [die]   \n",
       "4  31186339   Seneca Crane  [Gamemaker]   \n",
       "\n",
       "                                              active  \\\n",
       "0     [take, reveal, mean, form, present, beg, tell]   \n",
       "1                                             [kill]   \n",
       "2  [take, survive, drop, warn, run, shoot, presen...   \n",
       "3                           [draw, care, draw, trap]   \n",
       "4                                     [change, lock]   \n",
       "\n",
       "                                           patient  cluster  \n",
       "0                                          [force]       29  \n",
       "1                        [encounter, wound, shoot]       15  \n",
       "2  [give, find, torment, spare, force, tell, warn]        9  \n",
       "3                      [hear, stab, comfort, kill]        1  \n",
       "4                               [summon, convince]       14  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters =  pd.read_csv(\n",
    "    'data/character_clusters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.944085Z",
     "iopub.status.busy": "2023-11-16T22:04:05.943783Z",
     "iopub.status.idle": "2023-11-16T22:04:06.138476Z",
     "shell.execute_reply": "2023-11-16T22:04:06.137841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the clustered characters dataframe there are 74842 characters from 25664 movies\n"
     ]
    }
   ],
   "source": [
    "print(f\"In the clustered characters dataframe there are {len(characters)} characters from {len(set(characters['wiki_id'].values))} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\n",
    "    'data/MovieSummaries/movie.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'title', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the clustered characters with movie metadata dataframe there are 23911 characters from 6280 movies with the revenue data\n"
     ]
    }
   ],
   "source": [
    "characters_and_movies = characters.merge(movies, how='left', on='wiki_id')\n",
    "characters_and_movies = characters_and_movies[characters_and_movies['revenue'].notna()]\n",
    "\n",
    "print(f\"In the clustered characters with movie metadata dataframe there are {len(characters_and_movies)} characters from {len(set(characters_and_movies['wiki_id'].values))} movies with the revenue data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>adj</th>\n",
       "      <th>active</th>\n",
       "      <th>patient</th>\n",
       "      <th>cluster</th>\n",
       "      <th>freebase_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63974</th>\n",
       "      <td>21254702</td>\n",
       "      <td>Brian</td>\n",
       "      <td>[member]</td>\n",
       "      <td>[send, come]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>/m/05b_8_1</td>\n",
       "      <td>I Can Do Bad All by Myself</td>\n",
       "      <td>2009-09-11</td>\n",
       "      <td>51733921.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/06cvj\": \"Romantic comedy\", \"/m/01t_vv\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19516</th>\n",
       "      <td>4338749</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>[]</td>\n",
       "      <td>[treat, see, kidnap, replace, arrive, manage, ...</td>\n",
       "      <td>[contact, give, free, blame, tell]</td>\n",
       "      <td>2</td>\n",
       "      <td>/m/0bxxzb</td>\n",
       "      <td>I Spy</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>60279822.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>{\"/m/06b_j\": \"Russian Language\", \"/m/02h40lc\":...</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03k9fj\": \"Advent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64499</th>\n",
       "      <td>19226290</td>\n",
       "      <td>Judith</td>\n",
       "      <td>[wife]</td>\n",
       "      <td>[empty, apologize]</td>\n",
       "      <td>[]</td>\n",
       "      <td>18</td>\n",
       "      <td>/m/02r1c18</td>\n",
       "      <td>A Serious Man</td>\n",
       "      <td>2009-09-12</td>\n",
       "      <td>31312437.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/0880p\": \"Yiddish Language\", \"/m/02h40lc\":...</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\", \"/m/...</td>\n",
       "      <td>{\"/m/0vgkd\": \"Black comedy\", \"/m/04xvlr\": \"Per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wiki_id character       adj  \\\n",
       "63974  21254702     Brian  [member]   \n",
       "19516   4338749  Robinson        []   \n",
       "64499  19226290    Judith    [wife]   \n",
       "\n",
       "                                                  active  \\\n",
       "63974                                       [send, come]   \n",
       "19516  [treat, see, kidnap, replace, arrive, manage, ...   \n",
       "64499                                 [empty, apologize]   \n",
       "\n",
       "                                  patient  cluster freebase_id  \\\n",
       "63974                                  []        3  /m/05b_8_1   \n",
       "19516  [contact, give, free, blame, tell]        2   /m/0bxxzb   \n",
       "64499                                  []       18  /m/02r1c18   \n",
       "\n",
       "                            title release_date     revenue  runtime  \\\n",
       "63974  I Can Do Bad All by Myself   2009-09-11  51733921.0    113.0   \n",
       "19516                       I Spy   2002-11-01  60279822.0     96.0   \n",
       "64499               A Serious Man   2009-09-12  31312437.0    106.0   \n",
       "\n",
       "                                               languages  \\\n",
       "63974                 {\"/m/02h40lc\": \"English Language\"}   \n",
       "19516  {\"/m/06b_j\": \"Russian Language\", \"/m/02h40lc\":...   \n",
       "64499  {\"/m/0880p\": \"Yiddish Language\", \"/m/02h40lc\":...   \n",
       "\n",
       "                                               countries  \\\n",
       "63974          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "19516          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "64499  {\"/m/09c7w0\": \"United States of America\", \"/m/...   \n",
       "\n",
       "                                                  genres  \n",
       "63974  {\"/m/06cvj\": \"Romantic comedy\", \"/m/01t_vv\": \"...  \n",
       "19516  {\"/m/01jfsb\": \"Thriller\", \"/m/03k9fj\": \"Advent...  \n",
       "64499  {\"/m/0vgkd\": \"Black comedy\", \"/m/04xvlr\": \"Per...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_and_movies.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:06.267874Z",
     "iopub.status.busy": "2023-11-16T22:04:06.267502Z",
     "iopub.status.idle": "2023-11-16T22:04:06.292394Z",
     "shell.execute_reply": "2023-11-16T22:04:06.291761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>character</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6348</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Superman</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6349</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Batman</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Barda</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Kara</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Darkseid</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69321</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Riddler</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69322</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Batman</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69323</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Edward Nygma</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69324</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Bruce Wayne</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69325</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Robin</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title     character  cluster\n",
       "6348   Superman/Batman: Apocalypse      Superman       42\n",
       "6349   Superman/Batman: Apocalypse        Batman       42\n",
       "6350   Superman/Batman: Apocalypse         Barda       30\n",
       "6351   Superman/Batman: Apocalypse          Kara       42\n",
       "6352   Superman/Batman: Apocalypse      Darkseid       23\n",
       "...                            ...           ...      ...\n",
       "69321               Batman Forever       Riddler       42\n",
       "69322               Batman Forever        Batman       42\n",
       "69323               Batman Forever  Edward Nygma       17\n",
       "69324               Batman Forever   Bruce Wayne       41\n",
       "69325               Batman Forever         Robin       42\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_and_movies[characters_and_movies['title'].str.contains(\"Batman\")][['title', 'character', 'cluster']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice, that, probably, cluster number 42 is the cluster of super-heroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters interpretability\n",
    "For now we won't give particular names to each cluster. But we show, how to use data from Latent Dirichlet Allocation model to understand what is the meaning of each cluster. We can look at the most important topics (groups of words) for each cluster and conclude, what is the role of the character form a particular cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = json.load(open('data/words_by_topic.json', 'r'))\n",
    "lda_components = np.load('data/lda_components.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the cluster 0, the most important topic is patient verb from\n",
      "['ascend', 'bash', 'chase', 'climb', 'hit', 'jump', 'kick', 'knock', 'leap', 'move', 'nudge', 'pass', 'pull', 'push', 'run', 'slam', 'smash', 'step', 'turn']\n",
      "\n",
      "For the cluster 10, the most important topic is attribute from\n",
      "['alia', 'alias', 'aunt', 'babysit', 'babysitter', 'barmaid', 'betrothed', 'butler', 'codename', 'cousin', 'daughter', 'dote', 'elder', 'fiancee', 'fiancé', 'fiancée', 'goddaughter', 'granddaughter', 'grandson', 'housekeeper', 'husband', 'maid', 'name', 'nanny', 'nephew', 'nickname', 'niece', 'pseudonym', 'son', 'stepdaughter', 'stepson', 'uncle', 'widow', 'widowed', 'widower', 'wife']\n",
      "\n",
      "For the cluster 20, the most important topic is active verb from\n",
      "['accommodate', 'assemble', 'concoct', 'cover', 'decorate', 'divide', 'elaborate', 'equip', 'fabricate', 'follow', 'instal', 'install', 'merge', 'replace', 'replacement', 'set', 'split', 'unite', 'upgrade']\n",
      "\n",
      "For the cluster 30, the most important topic is active verb from\n",
      "['bind', 'bite', 'chew', 'chomp', 'fold', 'go', 'gobble', 'hang', 'huddle', 'lay', 'lick', 'lie', 'melt', 'pat', 'pluck', 'poke', 'rip', 'rub', 'sit', 'sniff', 'snort', 'soak', 'spit', 'suck', 'tear', 'wash', 'whip', 'wipe', 'yank']\n",
      "\n",
      "For the cluster 40, the most important topic is active verb from\n",
      "['attempt', 'ban', 'bid', 'bill', 'billy', 'order', 'plan', 'scheme']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 50, 10):\n",
    "    idx = lda_components[i].argmax()\n",
    "    feature_type = 'attribute'\n",
    "    if idx // 200 == 1:\n",
    "        feature_type = 'active verb'\n",
    "    elif idx // 200 == 2:\n",
    "        feature_type = 'patient verb'\n",
    "    print(f'For the cluster {i}, the most important topic is {feature_type} from')\n",
    "    print(topics_dict[str(idx % 200)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can see, that characters in cluster 0 are the onces who move a lot, while in cluster 10 characters are usually someones relative and characters in cluster 40 are some authority figures. Further, we will look at the top topics for each cluster to interpret, what are the common traits of the characters in one cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis of the actors' success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = pd.read_csv(\n",
    "    'data/MovieSummaries/character.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'release_date', 'character', 'date_of_birth', 'sex', 'height', '.','actor','age','character_map','..','...','....']\n",
    ")\n",
    "actors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict_to_list = lambda x: [value for key, value in eval(x).items()]\n",
    "movies['languages'] = movies['languages'].apply(map_dict_to_list)\n",
    "movies['countries'] = movies['countries'].apply(map_dict_to_list)\n",
    "movies['genres'] = movies['genres'].apply(map_dict_to_list)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which actors bring in the most money\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datas\n",
    "df_merged = actors.merge(movies, on=['wiki_id'], how='inner')\n",
    "\n",
    "# Clean data of movies without box offic revenue\n",
    "df_merged = df_merged.dropna(subset=['revenue'])\n",
    "\n",
    "# Determine the actor and sum the box office revenue\n",
    "actor_totalRevenue = df_merged.groupby(['actor'])['revenue'].agg(['sum', 'count']).reset_index()\n",
    "actor_totalRevenue.columns = ['actor', 'bo_revenue', 'Actor Count']\n",
    "\n",
    "# Sort the actor_revenue DataFrame in descending order\n",
    "actor_revenue_sort = actor_totalRevenue.sort_values(by='bo_revenue', ascending=False)\n",
    "\n",
    "#Extract only the top 20 best actors\n",
    "actor_top20 = actor_revenue_sort.head(20)\n",
    "\n",
    "# Merge the top 20 actors with original datas\n",
    "top20_actor_data = actor_top20.merge(df_merged[['actor', 'languages','sex']], on='actor', how='left')\n",
    "top20_actor_data = top20_actor_data.drop_duplicates(subset = ['actor'])\n",
    "top20_actor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data above\n",
    "actor_names = top20_actor_data['actor']\n",
    "revenues_total = top20_actor_data['bo_revenue']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actor_names, revenues_total)\n",
    "plt.xlabel('Actor Names')\n",
    "plt.ylabel('Total Box Office Revenue')\n",
    "plt.title('Top 10 Actors by Box Office Revenue')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the actor names for better readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data above, we are ranking the actors according to the sum of box office revenue of the movies they acted in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the main lead actors obtaining the highest revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculater_importance(x):\n",
    "    a = 0\n",
    "    for w in x[\"adj\"]:\n",
    "        a += w.isalpha()\n",
    "    for w in x[\"active\"]:\n",
    "        a += w.isalpha()\n",
    "    for w in x[\"patient\"]:\n",
    "        a += w.isalpha()\n",
    "    return a\n",
    "\n",
    "characters['importance'] = characters.apply(calculater_importance, axis=1)\n",
    "\n",
    "characters_with_importance = characters[['wiki_id', 'character', 'importance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_with_importance['importance_share'] = characters_with_importance['importance'] / characters_with_importance.groupby('wiki_id')['importance'].transform('sum')\n",
    "characters_with_importance['is_important'] = characters_with_importance['importance_share'] >= 0.2\n",
    "characters_with_importance.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charac_actor = df_merged[['wiki_id', 'character','actor','revenue']]\n",
    "\n",
    "# Include characters and actors together in the same dataset\n",
    "character_actor = df_charac_actor.merge(characters_with_importance, on=['wiki_id', 'character'], how='left')\n",
    "\n",
    "# Merge only the main charac of movies\\n\",\n",
    "main_character = character_actor[character_actor['is_important'] == True]\n",
    "\n",
    "#Add up the Box office revenue and count the occurance of movie appearance\n",
    "main_charac_mergedBOR = main_character.groupby(['actor'])['revenue'].agg(['sum', 'count']).reset_index()\n",
    "\n",
    "main_charac_sort = main_charac_mergedBOR.sort_values(by='sum', ascending=False)\n",
    "\n",
    "main_charac_top20 = main_charac_sort.head(20)\n",
    "main_charac_top20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the charts for main actors\\n\",\n",
    "main_charac_top20_names = main_charac_top20['actor']\n",
    "main_charac_revenue = main_charac_top20['sum']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(main_charac_top20_names,main_charac_revenue)\n",
    "plt.xlabel('Actor Names')\n",
    "plt.ylabel('Box Office Revenue')\n",
    "plt.title('Top 20 Main Characters by Box average Office Revenue')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the actor names for better readability\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top of the actors changed, and we see, that the actors look like those who we would expect to be successful (generally subjectively more famous than the previous top)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Male or female perform better in generating box office revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_actor_data = actor_revenue_sort.merge(actors[['actor', 'sex']], on='actor', how='left')\n",
    "gender_actor_data = gender_actor_data.drop_duplicates(subset = ['actor'])\n",
    "gender_actor_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for revenue between genders\n",
    "plt.figure(figsize=(10, 10))\n",
    "gender_boxplot = sns.boxplot(x=\"sex\", y=\"bo_revenue\", data=gender_actor_data.loc[gender_actor_data['sex'].isin(['M','F'])])\n",
    "\n",
    "# Set labels\n",
    "plt.ylabel(\"Movie box office revenue($)\")\n",
    "plt.title(\"Box office revenue between genders\")\n",
    "plt.ylim(0, 500000000)\n",
    "          \n",
    "#Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Given the variance and the 25th percentile, 75th percentile and medan, male actors drive higher box office revenue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the language used in top 50 films / Which language drive the highest revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top 100 movies\n",
    "film_sort = df_merged[['countries','languages','revenue','wiki_id']]\n",
    "film_sort = film_sort.drop_duplicates(subset = ['wiki_id'])\n",
    "film_sort = film_sort.sort_values(by='revenue', ascending=False)\n",
    "top100film = film_sort.head(100)\n",
    "\n",
    "# Split the language into new data frames\\\n",
    "df_split_languages = top100film.explode('languages')\n",
    "\n",
    "# Count the occurance of the languages\n",
    "language_counts = df_split_languages['languages'].value_counts()\n",
    "df_language_counts = pd.DataFrame({'Language': language_counts.index, 'Count': language_counts.values})\n",
    "\n",
    "# Plot the data\n",
    "df_language_counts.plot(kind='bar', x='Language', y='Count', figsize=(12, 6),log=True)\n",
    "plt.title('How many movies in the given language are in top 100 movies by revenue')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Count (logscale)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the genre of movies that earn the highest revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data to remove repeated movies\n",
    "df_clean_split_genres = df_merged[['title','genres','revenue','wiki_id']]\n",
    "df_clean_split_genres = df_clean_split_genres.drop_duplicates(subset = ['wiki_id'])\n",
    "\n",
    "# Split the genre into new data frames\n",
    "df_split_genre = df_clean_split_genres.explode('genres')[['title', 'revenue', 'genres']]\n",
    "\n",
    "# Find top genres\n",
    "top_genres = df_split_genre.groupby('genres').size().reset_index().sort_values(by=0, ascending=False)\n",
    "top_genres = top_genres.head(10)['genres'].values\n",
    "\n",
    "# Determine the actor and sum the box office revenue\n",
    "genre_totalRevenue = df_split_genre[df_split_genre['genres'].isin(top_genres)].groupby('genres')['revenue'].median().reset_index()\n",
    "\n",
    "# Sort the BOR in ascending order\n",
    "genre_totalRevenue = genre_totalRevenue.sort_values(by='revenue', ascending=False)\n",
    "\n",
    "genre = genre_totalRevenue['genres']\n",
    "genreRevenue = genre_totalRevenue['revenue']\n",
    "\n",
    "#Plot the charts\n",
    "plt.plot(genre, genreRevenue)\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Box office revenue')\n",
    "plt.title('Top 10 popular Genres sorted by median Box Office Revenue')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the actor names for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre prediction using clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revenue prediction using clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
