{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/EPFL/Fall 2023/ADA/project_repo/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.clustering import get_lda_clusters, get_vocab, word_topics_clustering, sort_meaningful, get_trf_clusters, topic_count\n",
    "from utils.clustering_evaluation import get_characters_with_tv_trop_info, variation_of_information, group_labels_by_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering methods comparison\n",
    "\n",
    "We use Variation of Information between our clusters and golden clusters from TV Tropes as suggested in [Learning Latent Personas of Film Characters](http://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf). This way we can compare our methods' performance with the original method performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA based clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>adj</th>\n",
       "      <th>active</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Peeta Mellark</td>\n",
       "      <td>[son]</td>\n",
       "      <td>[take, reveal, mean, form, present, beg, tell]</td>\n",
       "      <td>[force]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Cato</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kill]</td>\n",
       "      <td>[encounter, wound, shoot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Katniss</td>\n",
       "      <td>[]</td>\n",
       "      <td>[take, survive, drop, warn, run, shoot, presen...</td>\n",
       "      <td>[give, find, torment, spare, force, tell, warn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Rue</td>\n",
       "      <td>[die]</td>\n",
       "      <td>[draw, care, draw, trap]</td>\n",
       "      <td>[hear, stab, comfort, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Seneca Crane</td>\n",
       "      <td>[Gamemaker]</td>\n",
       "      <td>[change, lock]</td>\n",
       "      <td>[summon, convince]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wiki_id      character          adj  \\\n",
       "0  31186339  Peeta Mellark        [son]   \n",
       "1  31186339           Cato           []   \n",
       "2  31186339        Katniss           []   \n",
       "3  31186339            Rue        [die]   \n",
       "4  31186339   Seneca Crane  [Gamemaker]   \n",
       "\n",
       "                                              active  \\\n",
       "0     [take, reveal, mean, form, present, beg, tell]   \n",
       "1                                             [kill]   \n",
       "2  [take, survive, drop, warn, run, shoot, presen...   \n",
       "3                           [draw, care, draw, trap]   \n",
       "4                                     [change, lock]   \n",
       "\n",
       "                                           patient  \n",
       "0                                          [force]  \n",
       "1                        [encounter, wound, shoot]  \n",
       "2  [give, find, torment, spare, force, tell, warn]  \n",
       "3                      [hear, stab, comfort, kill]  \n",
       "4                               [summon, convince]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_attributes =  pd.read_csv(\n",
    "    'data/character_attributes.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "# select only the characters who have at least 3 liguistic features\n",
    "characters_attributes = sort_meaningful(characters_attributes, 3)\n",
    "\n",
    "characters_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_check, tv_tropes = get_characters_with_tv_trop_info(characters_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25 topics, 25 archetypes': 6.2466797099799205,\n",
       " '25 topics, 50 archetypes': 5.721030072070011,\n",
       " '25 topics, 100 archetypes': 5.2078476164448135,\n",
       " '50 topics, 25 archetypes': 6.3319648575061835,\n",
       " '50 topics, 50 archetypes': 5.666473591455292,\n",
       " '50 topics, 100 archetypes': 4.976150571899939,\n",
       " '100 topics, 25 archetypes': 6.349160556531042,\n",
       " '100 topics, 50 archetypes': 5.607356379575675,\n",
       " '100 topics, 100 archetypes': 4.898739702618948}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agglomerative_clusters_n = [25, 50, 100]\n",
    "n_components = [25, 50, 100]\n",
    "\n",
    "configs = {}\n",
    "config_base = {'characters': characters_to_check, 'min_freq': 5, 'max_freq':0.9}\n",
    "\n",
    "for alg_n in agglomerative_clusters_n:\n",
    "    for n in n_components:\n",
    "        config = config_base.copy()\n",
    "        config['clustering_algo'] = AgglomerativeClustering(n_clusters=alg_n, metric='cosine', linkage='complete')\n",
    "        config['n_components'] = n\n",
    "        configs[f'{alg_n} topics, {n} archetypes'] = config\n",
    "\n",
    "results_lda = {}\n",
    "for k, config in configs.items():\n",
    "    clusters = get_lda_clusters(**config)\n",
    "    results_lda[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_lda[k]}')\n",
    "\n",
    "clear_output(wait=True)\n",
    "results_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the results are even better (K=100, P=100, 5.42 in the paper and 4.9 here) than the results from the [paper](http://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf). That could indicate that using word2vec embeddings and Agglomerative clustering of the words to topics might be better suited for dividing the words into topics for the purpose of personas extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT based clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6002183</td>\n",
       "      <td>Horton</td>\n",
       "      <td>[1.0488402843475342, 0.3811729848384857, 0.645...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6002183</td>\n",
       "      <td>Ned McDodd</td>\n",
       "      <td>[-0.5622232556343079, -0.2521360516548157, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6002183</td>\n",
       "      <td>JoJo</td>\n",
       "      <td>[-0.7999439835548401, -0.4102073311805725, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6002183</td>\n",
       "      <td>Sally</td>\n",
       "      <td>[0.7803803086280823, -0.7006192207336426, 0.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6002183</td>\n",
       "      <td>LaRue</td>\n",
       "      <td>[-0.038770418614149094, 0.219954714179039, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wiki_id   character                                                emb\n",
       "0  6002183      Horton  [1.0488402843475342, 0.3811729848384857, 0.645...\n",
       "1  6002183  Ned McDodd  [-0.5622232556343079, -0.2521360516548157, -0....\n",
       "2  6002183        JoJo  [-0.7999439835548401, -0.4102073311805725, 0.6...\n",
       "3  6002183       Sally  [0.7803803086280823, -0.7006192207336426, 0.32...\n",
       "4  6002183       LaRue  [-0.038770418614149094, 0.219954714179039, -0...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_with_trf_emb =  pd.read_csv(\n",
    "    'data/trf_embeddings_for_labeled_characters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"emb\": lambda x: [float(k) for k in x.strip(\"[]\").replace(\"'\",\"\").split(\", \")]\n",
    "        }\n",
    "    )\n",
    "# Leave only those, who we compared on the previous step\n",
    "characters_with_trf_emb = characters_with_trf_emb[characters_with_trf_emb['wiki_id'].isin(characters_to_check['wiki_id'].values)]\n",
    "\n",
    "characters_with_trf_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_check_trf, tv_tropes = get_characters_with_tv_trop_info(characters_with_trf_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25 archetypes, agglomerative clustering': 6.126084917715467,\n",
       " '25 archetypes, kmeans clustering': 6.116164230254499,\n",
       " '50 archetypes, agglomerative clustering': 5.5954496618130625,\n",
       " '50 archetypes, kmeans clustering': 5.484842314253758,\n",
       " '100 archetypes, agglomerative clustering': 4.936886689856702,\n",
       " '100 archetypes, kmeans clustering': 4.809396999118923}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_trf = {}\n",
    "for n in n_components:\n",
    "    k = f'{n} archetypes, agglomerative clustering'\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=n, metric='euclidean', linkage='complete')\n",
    "    clusters = get_trf_clusters(characters_to_check_trf, agglomerative)\n",
    "    results_trf[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_trf[k]}')\n",
    "\n",
    "    k = f'{n} archetypes, kmeans clustering'\n",
    "    kmeans = KMeans(n_clusters=n)\n",
    "    clusters = get_trf_clusters(characters_to_check_trf, kmeans)\n",
    "    results_trf[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_trf[k]}')\n",
    "\n",
    "clear_output(wait=True)\n",
    "results_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of BERT embeddings based clustering are also better than the results from the paper. Still, obtaining these embeddings is slow, and the difference between this and previous method is not that big, so we will stick to the faster and more interpretable LDA based method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "For the character names and linguistic features extraction pipeline, please refer to `extract_character_attributes.ipynb`. And for the clusterization pipeline as well as the different clustering methods comparison refer to `clustering.ipynb`. For our initial analysis we will use 60 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>adj</th>\n",
       "      <th>active</th>\n",
       "      <th>patient</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Peeta Mellark</td>\n",
       "      <td>[son]</td>\n",
       "      <td>[take, reveal, mean, form, present, beg, tell]</td>\n",
       "      <td>[force]</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Cato</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kill]</td>\n",
       "      <td>[encounter, wound, shoot]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Katniss</td>\n",
       "      <td>[]</td>\n",
       "      <td>[take, survive, drop, warn, run, shoot, presen...</td>\n",
       "      <td>[give, find, torment, spare, force, tell, warn]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Rue</td>\n",
       "      <td>[die]</td>\n",
       "      <td>[draw, care, draw, trap]</td>\n",
       "      <td>[hear, stab, comfort, kill]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31186339</td>\n",
       "      <td>Seneca Crane</td>\n",
       "      <td>[Gamemaker]</td>\n",
       "      <td>[change, lock]</td>\n",
       "      <td>[summon, convince]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wiki_id      character          adj  \\\n",
       "0  31186339  Peeta Mellark        [son]   \n",
       "1  31186339           Cato           []   \n",
       "2  31186339        Katniss           []   \n",
       "3  31186339            Rue        [die]   \n",
       "4  31186339   Seneca Crane  [Gamemaker]   \n",
       "\n",
       "                                              active  \\\n",
       "0     [take, reveal, mean, form, present, beg, tell]   \n",
       "1                                             [kill]   \n",
       "2  [take, survive, drop, warn, run, shoot, presen...   \n",
       "3                           [draw, care, draw, trap]   \n",
       "4                                     [change, lock]   \n",
       "\n",
       "                                           patient  cluster  \n",
       "0                                          [force]       29  \n",
       "1                        [encounter, wound, shoot]       55  \n",
       "2  [give, find, torment, spare, force, tell, warn]        2  \n",
       "3                      [hear, stab, comfort, kill]        1  \n",
       "4                               [summon, convince]        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters =  pd.read_csv(\n",
    "    'data/character_clusters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the clustered characters dataframe there are 74842 characters from 25664 movies\n"
     ]
    }
   ],
   "source": [
    "print(f\"In the clustered characters dataframe there are {len(characters)} characters from {len(set(characters['wiki_id'].values))} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\n",
    "    'data/MovieSummaries/movie.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'title', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the clustered characters with movie metadata dataframe there are 23911 characters from 6280 movies with the revenue data\n"
     ]
    }
   ],
   "source": [
    "characters_and_movies = characters.merge(movies, how='left', on='wiki_id')\n",
    "characters_and_movies = characters_and_movies[characters_and_movies['revenue'].notna()]\n",
    "\n",
    "print(f\"In the clustered characters with movie metadata dataframe there are {len(characters_and_movies)} characters from {len(set(characters_and_movies['wiki_id'].values))} movies with the revenue data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>character</th>\n",
       "      <th>adj</th>\n",
       "      <th>active</th>\n",
       "      <th>patient</th>\n",
       "      <th>cluster</th>\n",
       "      <th>freebase_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>languages</th>\n",
       "      <th>countries</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45359</th>\n",
       "      <td>3771410</td>\n",
       "      <td>Clete Ferguson</td>\n",
       "      <td>[]</td>\n",
       "      <td>[begin, try, try]</td>\n",
       "      <td>[stalk]</td>\n",
       "      <td>35</td>\n",
       "      <td>/m/09_3yl</td>\n",
       "      <td>Revenge of the Creature</td>\n",
       "      <td>1955-05-11</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/0cq22z7\": \"Sci-Fi Horror\", \"/m/03npn\": \"H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64902</th>\n",
       "      <td>985304</td>\n",
       "      <td>Lana Marcus</td>\n",
       "      <td>[friend]</td>\n",
       "      <td>[enter, have, have, leave]</td>\n",
       "      <td>[]</td>\n",
       "      <td>12</td>\n",
       "      <td>/m/03wrqt</td>\n",
       "      <td>Deadly Blessing</td>\n",
       "      <td>1981-08-14</td>\n",
       "      <td>8279042.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35853</th>\n",
       "      <td>20937181</td>\n",
       "      <td>Sheryl</td>\n",
       "      <td>[man]</td>\n",
       "      <td>[go, convince, go, kidnap, encounter, force, d...</td>\n",
       "      <td>[chase, find, find, mutilate, tell]</td>\n",
       "      <td>56</td>\n",
       "      <td>/m/05b4__s</td>\n",
       "      <td>Timber Falls</td>\n",
       "      <td>2007</td>\n",
       "      <td>680299.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01q03\": \"Cult\", \"/m/03npn\": \"Horror\", \"/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>133574</td>\n",
       "      <td>Bill Daggett</td>\n",
       "      <td>[sheriff, little, gunfighter, little, little, ...</td>\n",
       "      <td>[give, disarm, beat, arrive, have, assemble, c...</td>\n",
       "      <td>[leave, stop]</td>\n",
       "      <td>41</td>\n",
       "      <td>/m/0_92w</td>\n",
       "      <td>Unforgiven</td>\n",
       "      <td>1992-08-03</td>\n",
       "      <td>159157447.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/0hfjk\": \"Western\", \"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40599</th>\n",
       "      <td>3439529</td>\n",
       "      <td>June Ellis</td>\n",
       "      <td>[patient]</td>\n",
       "      <td>[die]</td>\n",
       "      <td>[befriend]</td>\n",
       "      <td>34</td>\n",
       "      <td>/m/09cgnx</td>\n",
       "      <td>The Doctor</td>\n",
       "      <td>1991-07-24</td>\n",
       "      <td>38120905.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wiki_id       character  \\\n",
       "45359   3771410  Clete Ferguson   \n",
       "64902    985304     Lana Marcus   \n",
       "35853  20937181          Sheryl   \n",
       "7051     133574    Bill Daggett   \n",
       "40599   3439529      June Ellis   \n",
       "\n",
       "                                                     adj  \\\n",
       "45359                                                 []   \n",
       "64902                                           [friend]   \n",
       "35853                                              [man]   \n",
       "7051   [sheriff, little, gunfighter, little, little, ...   \n",
       "40599                                          [patient]   \n",
       "\n",
       "                                                  active  \\\n",
       "45359                                  [begin, try, try]   \n",
       "64902                         [enter, have, have, leave]   \n",
       "35853  [go, convince, go, kidnap, encounter, force, d...   \n",
       "7051   [give, disarm, beat, arrive, have, assemble, c...   \n",
       "40599                                              [die]   \n",
       "\n",
       "                                   patient  cluster freebase_id  \\\n",
       "45359                              [stalk]       35   /m/09_3yl   \n",
       "64902                                   []       12   /m/03wrqt   \n",
       "35853  [chase, find, find, mutilate, tell]       56  /m/05b4__s   \n",
       "7051                         [leave, stop]       41    /m/0_92w   \n",
       "40599                           [befriend]       34   /m/09cgnx   \n",
       "\n",
       "                         title release_date      revenue  runtime  \\\n",
       "45359  Revenge of the Creature   1955-05-11    1100000.0     82.0   \n",
       "64902          Deadly Blessing   1981-08-14    8279042.0    103.0   \n",
       "35853             Timber Falls         2007     680299.0    100.0   \n",
       "7051                Unforgiven   1992-08-03  159157447.0    131.0   \n",
       "40599               The Doctor   1991-07-24   38120905.0    122.0   \n",
       "\n",
       "                                languages  \\\n",
       "45359  {\"/m/02h40lc\": \"English Language\"}   \n",
       "64902  {\"/m/02h40lc\": \"English Language\"}   \n",
       "35853  {\"/m/02h40lc\": \"English Language\"}   \n",
       "7051   {\"/m/02h40lc\": \"English Language\"}   \n",
       "40599  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                                       countries  \\\n",
       "45359  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "64902  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "35853  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "7051   {\"/m/09c7w0\": \"United States of America\"}   \n",
       "40599  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "\n",
       "                                                  genres  \n",
       "45359  {\"/m/0cq22z7\": \"Sci-Fi Horror\", \"/m/03npn\": \"H...  \n",
       "64902  {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  \n",
       "35853  {\"/m/01q03\": \"Cult\", \"/m/03npn\": \"Horror\", \"/m...  \n",
       "7051      {\"/m/0hfjk\": \"Western\", \"/m/07s9rl0\": \"Drama\"}  \n",
       "40599                            {\"/m/07s9rl0\": \"Drama\"}  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_and_movies.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>character</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6348</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Superman</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6349</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Batman</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Barda</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Kara</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>Superman/Batman: Apocalypse</td>\n",
       "      <td>Darkseid</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69321</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Riddler</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69322</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Batman</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69323</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Edward Nygma</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69324</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Bruce Wayne</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69325</th>\n",
       "      <td>Batman Forever</td>\n",
       "      <td>Robin</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title     character  cluster\n",
       "6348   Superman/Batman: Apocalypse      Superman       42\n",
       "6349   Superman/Batman: Apocalypse        Batman       42\n",
       "6350   Superman/Batman: Apocalypse         Barda       30\n",
       "6351   Superman/Batman: Apocalypse          Kara       42\n",
       "6352   Superman/Batman: Apocalypse      Darkseid       23\n",
       "...                            ...           ...      ...\n",
       "69321               Batman Forever       Riddler       42\n",
       "69322               Batman Forever        Batman       42\n",
       "69323               Batman Forever  Edward Nygma       56\n",
       "69324               Batman Forever   Bruce Wayne       41\n",
       "69325               Batman Forever         Robin       42\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_and_movies[characters_and_movies['title'].str.contains(\"Batman\")][['title', 'character', 'cluster']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice, that, probably, cluster number 42 is the cluster of super-heroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis of the actors' success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre prediction using clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revenue prediction using clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
