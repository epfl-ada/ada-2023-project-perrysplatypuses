{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.183730Z",
     "iopub.status.busy": "2023-11-16T22:04:05.183555Z",
     "iopub.status.idle": "2023-11-16T22:04:05.197566Z",
     "shell.execute_reply": "2023-11-16T22:04:05.197108Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.199836Z",
     "iopub.status.busy": "2023-11-16T22:04:05.199502Z",
     "iopub.status.idle": "2023-11-16T22:04:05.594478Z",
     "shell.execute_reply": "2023-11-16T22:04:05.593913Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.clustering import get_lda_clusters, get_vocab, word_topics_clustering, sort_meaningful, get_trf_clusters, topic_count\n",
    "from utils.clustering_evaluation import get_characters_with_tv_trop_info, variation_of_information, group_labels_by_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering methods comparison\n",
    "\n",
    "We use Variation of Information between our clusters and golden clusters from TV Tropes as suggested in [Learning Latent Personas of Film Characters](http://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf). This way we can compare our methods' performance with the original method performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA based clustering\n",
    "For the character names and linguistic features extraction pipeline, please refer to `extract_character_attributes.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_attributes =  pd.read_csv(\n",
    "    'data/character_attributes.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "# select only the characters who have at least 3 liguistic features\n",
    "characters_attributes = sort_meaningful(characters_attributes, 3)\n",
    "\n",
    "characters_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_check, tv_tropes = get_characters_with_tv_trop_info(characters_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglomerative_clusters_n = [25, 50, 100]\n",
    "n_components = [25, 50, 100]\n",
    "\n",
    "configs = {}\n",
    "config_base = {'characters': characters_to_check, 'min_freq': 5, 'max_freq':0.9}\n",
    "\n",
    "for alg_n in agglomerative_clusters_n:\n",
    "    for n in n_components:\n",
    "        config = config_base.copy()\n",
    "        config['clustering_algo'] = AgglomerativeClustering(n_clusters=alg_n, metric='cosine', linkage='complete')\n",
    "        config['n_components'] = n\n",
    "        configs[f'{alg_n} topics, {n} archetypes'] = config\n",
    "\n",
    "results_lda = {}\n",
    "for k, config in configs.items():\n",
    "    clusters = get_lda_clusters(**config)\n",
    "    results_lda[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_lda[k]}')\n",
    "\n",
    "clear_output(wait=True)\n",
    "results_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that the results are even better (K=100, P=100, 5.42 in the paper and 4.9 here) than the results from the [paper](http://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf). That could indicate that using word2vec embeddings and Agglomerative clustering of the words to topics might be better suited for dividing the words into topics for the purpose of personas extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT based clustering\n",
    "\n",
    "For the embedding extraction see `utils/archive/transformer_embeddings.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_with_trf_emb =  pd.read_csv(\n",
    "    'data/trf_embeddings_for_labeled_characters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"emb\": lambda x: [float(k) for k in x.strip(\"[]\").replace(\"'\",\"\").split(\", \")]\n",
    "        }\n",
    "    )\n",
    "# Leave only those, who we compared on the previous step\n",
    "characters_with_trf_emb = characters_with_trf_emb[characters_with_trf_emb['wiki_id'].isin(characters_to_check['wiki_id'].values)]\n",
    "\n",
    "characters_with_trf_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_to_check_trf, tv_tropes = get_characters_with_tv_trop_info(characters_with_trf_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_trf = {}\n",
    "for n in n_components:\n",
    "    k = f'{n} archetypes, agglomerative clustering'\n",
    "    agglomerative = AgglomerativeClustering(n_clusters=n, metric='euclidean', linkage='complete')\n",
    "    clusters = get_trf_clusters(characters_to_check_trf, agglomerative)\n",
    "    results_trf[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_trf[k]}')\n",
    "\n",
    "    k = f'{n} archetypes, kmeans clustering'\n",
    "    kmeans = KMeans(n_clusters=n)\n",
    "    clusters = get_trf_clusters(characters_to_check_trf, kmeans)\n",
    "    results_trf[k] = variation_of_information(group_labels_by_clusters(clusters), tv_tropes)\n",
    "    print(k, f'VI = {results_trf[k]}')\n",
    "\n",
    "clear_output(wait=True)\n",
    "results_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of BERT embeddings based clustering are also better than the results from the paper. Still, obtaining these embeddings is slow, and the difference between this and previous method is not that big, so we will stick to the faster and more interpretable LDA based method.\n",
    "\n",
    "**Comparison Table**\n",
    "\n",
    "|                      |Paper K=100, P=100| LDA-based clustering  K=100, P=100| BERT-based kmeans clustering P=100|\n",
    "|------------------------|------------------|-----------------------------------|-----------------------------------|\n",
    "|Variation of Information|              5.42|                               4.90|                              ~4.80|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "For the clusterization pipeline as well as the different clustering methods comparison refer to `clustering.ipynb`. For our initial analysis we will use 50 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.597362Z",
     "iopub.status.busy": "2023-11-16T22:04:05.596898Z",
     "iopub.status.idle": "2023-11-16T22:04:05.941635Z",
     "shell.execute_reply": "2023-11-16T22:04:05.940975Z"
    }
   },
   "outputs": [],
   "source": [
    "characters =  pd.read_csv(\n",
    "    'data/character_clusters.csv', \n",
    "    index_col=0,\n",
    "    converters={\n",
    "        \"adj\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"), # need this to read list columns from csv\n",
    "        \"active\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \"),\n",
    "        \"patient\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "        }\n",
    "    )\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:05.944085Z",
     "iopub.status.busy": "2023-11-16T22:04:05.943783Z",
     "iopub.status.idle": "2023-11-16T22:04:06.138476Z",
     "shell.execute_reply": "2023-11-16T22:04:06.137841Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"In the clustered characters dataframe there are {len(characters)} characters from {len(set(characters['wiki_id'].values))} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\n",
    "    'data/MovieSummaries/movie.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'title', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_and_movies = characters.merge(movies, how='left', on='wiki_id')\n",
    "characters_and_movies = characters_and_movies[characters_and_movies['revenue'].notna()]\n",
    "\n",
    "print(f\"In the clustered characters with movie metadata dataframe there are {len(characters_and_movies)} characters from {len(set(characters_and_movies['wiki_id'].values))} movies with the revenue data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_and_movies.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T22:04:06.267874Z",
     "iopub.status.busy": "2023-11-16T22:04:06.267502Z",
     "iopub.status.idle": "2023-11-16T22:04:06.292394Z",
     "shell.execute_reply": "2023-11-16T22:04:06.291761Z"
    }
   },
   "outputs": [],
   "source": [
    "characters_and_movies[characters_and_movies['title'].str.contains(\"Batman\")][['title', 'character', 'cluster']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice, that, probably, cluster number 42 is the cluster of super-heroes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters interpretability\n",
    "For now we won't give particular names to each cluster. But we show, how to use data from Latent Dirichlet Allocation model to understand what is the meaning of each cluster. We can look at the most important topics (groups of words) for each cluster and conclude, what is the role of the character form a particular cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dict = json.load(open('data/words_by_topic.json', 'r'))\n",
    "lda_components = np.load('data/lda_components.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 50, 10):\n",
    "    idx = lda_components[i].argmax()\n",
    "    feature_type = 'attribute'\n",
    "    if idx // 200 == 1:\n",
    "        feature_type = 'active verb'\n",
    "    elif idx // 200 == 2:\n",
    "        feature_type = 'patient verb'\n",
    "    print(f'For the cluster {i}, the most important topic is {feature_type} from')\n",
    "    print(topics_dict[str(idx % 200)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can see, that characters in cluster 0 are the onces who move a lot, while in cluster 10 characters are usually someones relative and characters in cluster 40 are some authority figures. Further, we will look at the top topics for each cluster to interpret, what are the common traits of the characters in one cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial analysis of the actors' success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = pd.read_csv(\n",
    "    'data/MovieSummaries/character.metadata.tsv', \n",
    "    sep='\\t', \n",
    "    names=['wiki_id', 'freebase_id', 'release_date', 'character', 'date_of_birth', 'sex', 'height', '.','actor','age','character_map','..','...','....']\n",
    ")\n",
    "actors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict_to_list = lambda x: [value for key, value in eval(x).items()]\n",
    "movies['languages'] = movies['languages'].apply(map_dict_to_list)\n",
    "movies['countries'] = movies['countries'].apply(map_dict_to_list)\n",
    "movies['genres'] = movies['genres'].apply(map_dict_to_list)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which actors bring in the most money\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datas\n",
    "df_merged = actors.merge(movies, on=['wiki_id'], how='inner')\n",
    "\n",
    "# Clean data of movies without box offic revenue\n",
    "df_merged = df_merged.dropna(subset=['revenue'])\n",
    "\n",
    "# Determine the actor and sum the box office revenue\n",
    "actor_totalRevenue = df_merged.groupby(['actor'])['revenue'].agg(['sum', 'count']).reset_index()\n",
    "actor_totalRevenue.columns = ['actor', 'bo_revenue', 'Actor Count']\n",
    "\n",
    "# Sort the actor_revenue DataFrame in descending order\n",
    "actor_revenue_sort = actor_totalRevenue.sort_values(by='bo_revenue', ascending=False)\n",
    "\n",
    "#Extract only the top 20 best actors\n",
    "actor_top20 = actor_revenue_sort.head(20)\n",
    "\n",
    "# Merge the top 20 actors with original datas\n",
    "top20_actor_data = actor_top20.merge(df_merged[['actor', 'languages','sex']], on='actor', how='left')\n",
    "top20_actor_data = top20_actor_data.drop_duplicates(subset = ['actor'])\n",
    "top20_actor_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data above\n",
    "actor_names = top20_actor_data['actor']\n",
    "revenues_total = top20_actor_data['bo_revenue']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actor_names, revenues_total)\n",
    "plt.xlabel('Actor Names')\n",
    "plt.ylabel('Total Box Office Revenue')\n",
    "plt.title('Top 10 Actors by Box Office Revenue for the Movies They Acted In')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the actor names for better readability\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data above, we are ranking the actors according to the sum of the box office revenue from the movies in which they acted, without considering whether it was a first, second, or episodic role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the main lead actors obtaining the highest revenue\n",
    "\n",
    "Let's consider the weight for every role as a share of words in the plot that is related to the specific character. Then, let's make the simple assumption that all revenue is created thanks to the characters from the plot and calculate how much money corresponds to every actor's role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculater_importance(x):\n",
    "    a = 0\n",
    "    for w in x[\"adj\"]:\n",
    "        a += w.isalpha()\n",
    "    for w in x[\"active\"]:\n",
    "        a += w.isalpha()\n",
    "    for w in x[\"patient\"]:\n",
    "        a += w.isalpha()\n",
    "    return a\n",
    "\n",
    "characters['importance'] = characters.apply(calculater_importance, axis=1)\n",
    "\n",
    "characters_with_importance = characters[['wiki_id', 'character', 'importance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_with_importance['importance_share'] = characters_with_importance['importance'] / characters_with_importance.groupby('wiki_id')['importance'].transform('sum')\n",
    "characters_with_importance['is_important'] = characters_with_importance['importance_share'] >= 0.2\n",
    "characters_with_importance.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_charac_actor = df_merged[['wiki_id', 'character','actor','revenue']]\n",
    "\n",
    "# Include characters and actors together in the same dataset\n",
    "character_actor = df_charac_actor.merge(characters_with_importance, on=['wiki_id', 'character'], how='left')\n",
    "\n",
    "# Merge only the main charac of movies\\n\",\n",
    "main_character = character_actor[character_actor['is_important'] == True]\n",
    "\n",
    "#Add up the Box office revenue and count the occurance of movie appearance\n",
    "main_charac_mergedBOR = main_character.groupby(['actor'])['revenue'].agg(['sum', 'count']).reset_index()\n",
    "\n",
    "main_charac_sort = main_charac_mergedBOR.sort_values(by='sum', ascending=False)\n",
    "\n",
    "main_charac_top20 = main_charac_sort.head(20)\n",
    "main_charac_top20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the charts for main actors\\n\",\n",
    "main_charac_top20_names = main_charac_top20['actor']\n",
    "main_charac_revenue = main_charac_top20['sum']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(main_charac_top20_names,main_charac_revenue)\n",
    "plt.xlabel('Actor Names')\n",
    "plt.ylabel('Box Office Revenue')\n",
    "plt.title('Top 20 Main Characters by Box average Office Revenue')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the actor names for better readability\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top of the actors changed, and we see, that the actors look like those who we would expect to be successful (generally subjectively more famous than the previous top)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the language used in top 50 films / Which language drive the highest revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top 100 movies\n",
    "film_sort = df_merged[['countries','languages','revenue','wiki_id']]\n",
    "film_sort = film_sort.drop_duplicates(subset = ['wiki_id'])\n",
    "film_sort = film_sort.sort_values(by='revenue', ascending=False)\n",
    "top100film = film_sort.head(100)\n",
    "\n",
    "# Split the languages into new data frame\n",
    "df_split_languages = top100film.explode('languages')\n",
    "\n",
    "# Count the occurrence of the languages\n",
    "language_counts = df_split_languages['languages'].value_counts()\n",
    "df_language_counts = pd.DataFrame({'Language': language_counts.index, 'Count': language_counts.values})\n",
    "\n",
    "# Plot the data\n",
    "ax = df_language_counts.plot(kind='bar', x='Language', y='Count', figsize=(12, 6),logy=True)\n",
    "plt.title('How many movies in the given language are in top 100 movies by revenue')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Count (logscale)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.bar_label(ax.containers[0], label_type='edge')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a reasonable patter: English is almost everywhere, followed by wide-distributed languages like Spanish and French, and many languages that are used in only one movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the genre of movies that earn the highest revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data to remove repeated movies\n",
    "df_clean_split_genres = df_merged[['title','genres','revenue','wiki_id']]\n",
    "df_clean_split_genres = df_clean_split_genres.drop_duplicates(subset = ['wiki_id'])\n",
    "\n",
    "# Split the genre into new data frames\n",
    "df_split_genre = df_clean_split_genres.explode('genres')[['title', 'revenue', 'genres']]\n",
    "\n",
    "# Find top genres\n",
    "top_genres = df_split_genre.groupby('genres').size().reset_index().sort_values(by=0, ascending=False)\n",
    "top_genres = top_genres.head(10)['genres'].values\n",
    "\n",
    "# Determine the actor and sum the box office revenue\n",
    "genre_totalRevenue = df_split_genre[df_split_genre['genres'].isin(top_genres)].groupby('genres')['revenue'].median().reset_index()\n",
    "\n",
    "# Sort the BOR in ascending order\n",
    "genre_totalRevenue = genre_totalRevenue.sort_values(by='revenue', ascending=False)\n",
    "\n",
    "genre = genre_totalRevenue['genres']\n",
    "genreRevenue = genre_totalRevenue['revenue']\n",
    "\n",
    "#Plot the charts\n",
    "plt.plot(genre, genreRevenue)\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Box office revenue')\n",
    "plt.title('Top 10 popular Genres sorted by median Box Office Revenue')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate the actor names for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre-cluster correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_and_movies_with_genres = characters.merge(movies, how='left', on='wiki_id')\n",
    "characters_and_movies_with_genres = characters_and_movies_with_genres[characters_and_movies_with_genres['genres'].notna()]\n",
    "characters_and_movies_with_genres = characters_and_movies_with_genres[['wiki_id', 'title', 'character', 'cluster', 'genres']]\n",
    "characters_and_movies_with_genres.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_and_movies_with_genres = characters_and_movies_with_genres.explode('genres')\n",
    "characters_and_movies_with_genres = characters_and_movies_with_genres[characters_and_movies_with_genres['genres'].isin(top_genres)]\n",
    "characters_and_movies_with_genres.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_genre_table = characters_and_movies_with_genres[['cluster', 'genres']].groupby(['cluster', 'genres']).size().reset_index()\n",
    "cluster_genre_table = cluster_genre_table.pivot(index='cluster', columns='genres', values=0)\n",
    "cluster_genre_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "table = cluster_genre_table[['Romantic comedy', 'Thriller']].values\n",
    "res = chi2_contingency(table)\n",
    "print(f'pvalue of the test with H0: cluster distribution is the same in Romantic comedy\tand Thriller films: {res[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revenue prediction using clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, We'll make a table of what archetypal characters each film contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\"wiki_id\",\"Freebase movie ID\",\" Movie name\",\"Movie release date\", \"MovieBoxOfficeRevenue\",\"Movie runtime\",\"Movie languages\",\"Movie countries\",\"Movie genres\" ]\n",
    "df_movies = pd.read_csv(\"data/MovieSummaries/movie.metadata.tsv\", sep='\\t',names= colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_clusters = pd.read_csv(\"data/character_clusters.csv\")\n",
    "df_clusters = df_clusters.drop(df_clusters.columns[[0,3,4,5]], axis=1) # dropping unneccesary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging datasets\n",
    "df_merged = pd.merge(df_clusters, df_movies, on='wiki_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column for each archetypes. And they will take binary number.\n",
    "for i in range(1,51):\n",
    "    df_merged['archetype{}'.format(i)]=df_merged['cluster'].map(lambda x: 1 if x== i else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the movie include the archetype[i], then the column archetype[i] will take 1 , otherwise 0.\n",
    "def dummy(s):\n",
    "    if sum(s)>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# this is just an opperation for getting Box office value after a groupby operation.\n",
    "def boxoffice(s):\n",
    "    return sum(s)/len(s)\n",
    "\n",
    "string= ''    \n",
    "for i in range(1,51):\n",
    "    string = string + '\\'archetype' +str(i) +'\\':dummy,'\n",
    "string = string[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moviearchetypes = df_merged.groupby('wiki_id').agg({'MovieBoxOfficeRevenue':boxoffice,'archetype1':dummy,'archetype2':dummy,'archetype3':dummy,'archetype4':dummy,'archetype5':dummy,'archetype6':dummy,'archetype7':dummy,'archetype8':dummy,'archetype9':dummy,'archetype10':dummy,'archetype11':dummy,'archetype12':dummy,'archetype13':dummy,'archetype14':dummy,'archetype15':dummy,'archetype16':dummy,'archetype17':dummy,'archetype18':dummy,'archetype19':dummy,'archetype20':dummy,'archetype21':dummy,'archetype22':dummy,'archetype23':dummy,'archetype24':dummy,'archetype25':dummy,'archetype26':dummy,'archetype27':dummy,'archetype28':dummy,'archetype29':dummy,'archetype30':dummy,'archetype31':dummy,'archetype32':dummy,'archetype33':dummy,'archetype34':dummy,'archetype35':dummy,'archetype36':dummy,'archetype37':dummy,'archetype38':dummy,'archetype39':dummy,'archetype40':dummy,'archetype41':dummy,'archetype42':dummy,'archetype43':dummy,'archetype44':dummy,'archetype45':dummy,'archetype46':dummy,'archetype47':dummy,'archetype48':dummy,'archetype49':dummy,'archetype50':dummy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the raw without Box Office value\n",
    "df_moviearchetypes = df_moviearchetypes.dropna(subset=['MovieBoxOfficeRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieBoxOfficeRevenue</th>\n",
       "      <th>archetype1</th>\n",
       "      <th>archetype2</th>\n",
       "      <th>archetype3</th>\n",
       "      <th>archetype4</th>\n",
       "      <th>archetype5</th>\n",
       "      <th>archetype6</th>\n",
       "      <th>archetype7</th>\n",
       "      <th>archetype8</th>\n",
       "      <th>archetype9</th>\n",
       "      <th>...</th>\n",
       "      <th>archetype41</th>\n",
       "      <th>archetype42</th>\n",
       "      <th>archetype43</th>\n",
       "      <th>archetype44</th>\n",
       "      <th>archetype45</th>\n",
       "      <th>archetype46</th>\n",
       "      <th>archetype47</th>\n",
       "      <th>archetype48</th>\n",
       "      <th>archetype49</th>\n",
       "      <th>archetype50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wiki_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3037944</th>\n",
       "      <td>18.369109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464189</th>\n",
       "      <td>15.201805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30818824</th>\n",
       "      <td>17.753526</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856981</th>\n",
       "      <td>15.048241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51888</th>\n",
       "      <td>19.977080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251161</th>\n",
       "      <td>17.093348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>17.278085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28880684</th>\n",
       "      <td>18.777314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474328</th>\n",
       "      <td>18.165999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921301</th>\n",
       "      <td>14.391003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MovieBoxOfficeRevenue  archetype1  archetype2  archetype3  \\\n",
       "wiki_id                                                               \n",
       "3037944               18.369109           0           0           0   \n",
       "464189                15.201805           0           0           0   \n",
       "30818824              17.753526           1           0           0   \n",
       "4856981               15.048241           1           0           0   \n",
       "51888                 19.977080           0           0           0   \n",
       "2251161               17.093348           0           0           0   \n",
       "8481                  17.278085           0           0           0   \n",
       "28880684              18.777314           0           0           0   \n",
       "1474328               18.165999           0           0           0   \n",
       "921301                14.391003           0           0           0   \n",
       "\n",
       "          archetype4  archetype5  archetype6  archetype7  archetype8  \\\n",
       "wiki_id                                                                \n",
       "3037944            0           0           0           0           0   \n",
       "464189             0           0           0           1           0   \n",
       "30818824           0           1           0           0           0   \n",
       "4856981            0           0           0           0           0   \n",
       "51888              0           0           0           1           0   \n",
       "2251161            0           0           0           0           0   \n",
       "8481               0           0           0           0           0   \n",
       "28880684           0           0           0           0           0   \n",
       "1474328            0           0           0           0           0   \n",
       "921301             0           0           0           0           0   \n",
       "\n",
       "          archetype9  ...  archetype41  archetype42  archetype43  archetype44  \\\n",
       "wiki_id               ...                                                       \n",
       "3037944            0  ...            0            0            0            0   \n",
       "464189             0  ...            0            0            1            0   \n",
       "30818824           0  ...            0            0            0            0   \n",
       "4856981            0  ...            0            0            0            0   \n",
       "51888              0  ...            0            0            0            0   \n",
       "2251161            0  ...            0            1            1            0   \n",
       "8481               0  ...            0            0            0            0   \n",
       "28880684           1  ...            0            0            0            0   \n",
       "1474328            0  ...            0            0            0            0   \n",
       "921301             0  ...            0            0            0            0   \n",
       "\n",
       "          archetype45  archetype46  archetype47  archetype48  archetype49  \\\n",
       "wiki_id                                                                     \n",
       "3037944             0            0            0            0            0   \n",
       "464189              0            0            0            0            0   \n",
       "30818824            0            0            0            0            0   \n",
       "4856981             0            0            1            0            0   \n",
       "51888               1            0            1            0            0   \n",
       "2251161             0            0            0            0            0   \n",
       "8481                1            0            0            0            1   \n",
       "28880684            0            0            0            0            0   \n",
       "1474328             0            0            0            0            0   \n",
       "921301              0            0            0            0            0   \n",
       "\n",
       "          archetype50  \n",
       "wiki_id                \n",
       "3037944             0  \n",
       "464189              0  \n",
       "30818824            0  \n",
       "4856981             0  \n",
       "51888               0  \n",
       "2251161             0  \n",
       "8481                0  \n",
       "28880684            0  \n",
       "1474328             0  \n",
       "921301              0  \n",
       "\n",
       "[10 rows x 51 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#table will look like this\n",
    "df_moviearchetypes.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got the data.\n",
    "\n",
    "Our purpose is to create a linear regression model with each archetype as a variable to predict the log of the box office revenue.\n",
    "\n",
    "We will use linear regression model and least square method to fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply log to boxoffice\n",
    "df_moviearchetypes['MovieBoxOfficeRevenue'] = df_moviearchetypes['MovieBoxOfficeRevenue'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The number of archetypes\n",
    "n = 50\n",
    "\n",
    "model_str = \"MovieBoxOfficeRevenue ~ \"\n",
    "for i in range(1,n+1):\n",
    "    model_str += \"C(archetype\" + str(i) + \")+\"\n",
    "\n",
    "model_str_without_interaction = model_str.strip(\"+\")\n",
    "\n",
    "for i in range(1,n):\n",
    "    for j in range(i+1, n+1):\n",
    "        model_str += \"C(archetype\" + str(i) + \"):C(archetype\" + str(j) + \")+\"\n",
    "\n",
    "model_str = model_str.strip(\"+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the model\n",
    "mod = smf.ols(formula = model_str_without_interaction, data = df_moviearchetypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model (adding a random seed ensuring consistency)\n",
    "np.random.seed(2)\n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09672056186741684"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                                  0.000000\n",
       "C(archetype1)[T.1]                         0.001113\n",
       "C(archetype2)[T.1]                         0.000104\n",
       "C(archetype3)[T.1]                         0.001518\n",
       "C(archetype4)[T.1]                         0.136977\n",
       "                                             ...   \n",
       "C(archetype46)[T.1]:C(archetype48)[T.1]    0.348726\n",
       "C(archetype46)[T.1]:C(archetype49)[T.1]    0.948147\n",
       "C(archetype47)[T.1]:C(archetype48)[T.1]    0.932223\n",
       "C(archetype47)[T.1]:C(archetype49)[T.1]    0.577750\n",
       "C(archetype48)[T.1]:C(archetype49)[T.1]    0.460055\n",
       "Length: 1226, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is very low.\n",
    "The model is not accurate.\n",
    "But we can still select which of those archetypes might have an effect on box office revenue by considering the p-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will add interaction terms and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols(formula = model_str, data = df_moviearchetypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2504170467732182"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is still low but  better than the last one. We can conclude that revenue prediction by archetype combination could be prospective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
